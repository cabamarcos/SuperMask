{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0142d840",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from utils.apply_mask_alexnet import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1ea690",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuración\n",
    "batch_size = 64\n",
    "threshold_accuracy = 0.60\n",
    "sparsity_percentage = 0.1  # Porcentaje de pesos a conservar (más altos)\n",
    "max_epochs_before_restart = 70\n",
    "min_accuracy_before_restart = 0.50  # 50% accuracy mínima\n",
    "early_restart_epoch = 30\n",
    "early_restart_accuracy = 0.40  # 40% accuracy en época 30\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ca4f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset Animals10\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "data_dir = \"../data/animals10\"\n",
    "\n",
    "train_dataset = datasets.ImageFolder(root=os.path.join(data_dir, \"train\"), transform=transform)\n",
    "test_dataset = datasets.ImageFolder(root=os.path.join(data_dir, \"test\"), transform=transform)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75603446",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = models.alexnet(pretrained=False)\n",
    "net.classifier[6] = nn.Linear(net.classifier[6].in_features, 10)\n",
    "\n",
    "mask = models.alexnet(pretrained=False)\n",
    "mask.classifier[6] = nn.Linear(mask.classifier[6].in_features, 10)\n",
    "\n",
    "net.to(device)\n",
    "mask.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1288db31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Congelar los parámetros de net (no se entrenarán)\n",
    "for param in net.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc636eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(mask.parameters(), lr=0.001)\n",
    "epoch = 0\n",
    "saved = False\n",
    "losses = []\n",
    "accuracies = []\n",
    "restart_count = 0\n",
    "\n",
    "while True:\n",
    "    # Reinicializar si es necesario (verificación en época 70)\n",
    "    if epoch >= max_epochs_before_restart:\n",
    "        if len(accuracies) == 0 or max(accuracies) < min_accuracy_before_restart * 100:\n",
    "            restart_count += 1\n",
    "            print(f\"\\n!!! RESTART {restart_count} !!!\")\n",
    "            print(f\"No se alcanzó {min_accuracy_before_restart*100}% de accuracy en {max_epochs_before_restart} épocas.\")\n",
    "            print(\"Reinicializando net y máscara, y reiniciando el entrenamiento...\")\n",
    "            \n",
    "            # Reinicializar net (nueva inicialización aleatoria)\n",
    "            net = models.alexnet(pretrained=False)\n",
    "            net.classifier[6] = nn.Linear(net.classifier[6].in_features, 10)\n",
    "            net.to(device)\n",
    "            \n",
    "            # Congelar los parámetros de net\n",
    "            for param in net.parameters():\n",
    "                param.requires_grad = False\n",
    "            \n",
    "            # Reinicializar la máscara\n",
    "            mask = models.alexnet(pretrained=False)\n",
    "            mask.classifier[6] = nn.Linear(mask.classifier[6].in_features, 10)\n",
    "            mask.to(device)\n",
    "            \n",
    "            # Reinicializar el optimizador\n",
    "            optimizer = optim.Adam(mask.parameters(), lr=0.001)\n",
    "            \n",
    "            # Reinicializar métricas\n",
    "            epoch = 0\n",
    "            losses = []\n",
    "            accuracies = []\n",
    "            saved = False\n",
    "    \n",
    "    # Verificación de reinicio temprano en época 30\n",
    "    if epoch == early_restart_epoch:\n",
    "        if len(accuracies) == 0 or max(accuracies) < early_restart_accuracy * 100:\n",
    "            restart_count += 1\n",
    "            print(f\"\\n!!! EARLY RESTART {restart_count} !!!\")\n",
    "            print(f\"No se alcanzó {early_restart_accuracy*100}% de accuracy en época {early_restart_epoch}.\")\n",
    "            print(\"Reinicializando net y máscara, y reiniciando el entrenamiento...\")\n",
    "            \n",
    "            # Reinicializar net (nueva inicialización aleatoria)\n",
    "            net = models.alexnet(pretrained=False)\n",
    "            net.classifier[6] = nn.Linear(net.classifier[6].in_features, 10)\n",
    "            net.to(device)\n",
    "            \n",
    "            # Congelar los parámetros de net\n",
    "            for param in net.parameters():\n",
    "                param.requires_grad = False\n",
    "            \n",
    "            # Reinicializar la máscara\n",
    "            mask = models.alexnet(pretrained=False)\n",
    "            mask.classifier[6] = nn.Linear(mask.classifier[6].in_features, 10)\n",
    "            mask.to(device)\n",
    "            \n",
    "            # Reinicializar el optimizador\n",
    "            optimizer = optim.Adam(mask.parameters(), lr=0.001)\n",
    "            \n",
    "            # Reinicializar métricas\n",
    "            epoch = 0\n",
    "            losses = []\n",
    "            accuracies = []\n",
    "            saved = False\n",
    "    \n",
    "    masked_model = MaskedForward(net, mask, sparsity_percentage).to(device)\n",
    "    # Guardar copia de los pesos de net para verificar que no cambian\n",
    "    # net_before = [p.clone().detach() for p in net.parameters()]\n",
    "    masked_model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    epoch += 1\n",
    "\n",
    "    print(f\"\\n===== Epoch {epoch} (Restart {restart_count}) =====\")\n",
    "\n",
    "        # Guardar copia de los pesos de mask\n",
    "    # mask_before = [p.clone().detach() for p in mask.parameters()]\n",
    "\n",
    "    for batch_idx, (images, labels) in enumerate(train_loader):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "    \n",
    "        optimizer.zero_grad()\n",
    "        outputs = masked_model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "\n",
    "        # # Verificar gradientes\n",
    "        # for name, param in mask.named_parameters():\n",
    "        #     if param.grad is not None:\n",
    "        #         print(f\"[Grad] {name}: grad norm = {param.grad.norm().item():.6f}\")\n",
    "        #     else:\n",
    "        #         print(f\"[Grad] {name}: NO grad\")\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        # if batch_idx % 10 == 0:\n",
    "        #     print(f\"Batch {batch_idx}, Loss: {loss.item():.4f}\")\n",
    "\n",
    "    avg_loss = running_loss / len(train_loader)\n",
    "    losses.append(avg_loss)\n",
    "\n",
    "    # Evaluación\n",
    "    masked_model.eval()\n",
    "    correct, total = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = masked_model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = 100.0 * correct / total\n",
    "    accuracies.append(accuracy)\n",
    "\n",
    "    #     # Verificar cambios en los parámetros de mask\n",
    "    # for (before, after), name in zip(zip(mask_before, mask.parameters()), mask.state_dict().keys()):\n",
    "    #     delta = (after - before).abs().sum().item()\n",
    "    #     print(f\"[Update] {name}: Δ = {delta:.6f}\")\n",
    "\n",
    "    # # Verificar que net no ha sido modificado\n",
    "    # for (before, after), name in zip(zip(net_before, net.parameters()), net.state_dict().keys()):\n",
    "    #     delta = (after - before).abs().sum().item()\n",
    "    #     print(f\"[Check Net] {name}: Δ = {delta:.6f}\")\n",
    "\n",
    "    print(f\"Epoch {epoch}: Avg Loss = {avg_loss:.4f}, Test Accuracy = {accuracy:.2f}%\")\n",
    "\n",
    "    if accuracy >= threshold_accuracy * 100:\n",
    "        print(\"Reached target accuracy. Stopping training.\")\n",
    "        if not saved:\n",
    "            # Guardar net y mask\n",
    "            torch.save(net.state_dict(), \"net.pth\")\n",
    "            torch.save(mask.state_dict(), \"mask.pth\")\n",
    "            print(f\"Models saved)\")\n",
    "            saved = True\n",
    "        else:\n",
    "            print(\"Model already saved, skipping save.\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9dfcbb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gráficos de pérdida y precisión en una sola figura\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Gráfico de pérdida\n",
    "ax1.plot(range(1, len(losses)+1), losses, label='Loss', color='red')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.set_title('Training Loss per Epoch')\n",
    "ax1.legend()\n",
    "ax1.grid(True)\n",
    "\n",
    "# Gráfico de precisión\n",
    "ax2.plot(range(1, len(accuracies)+1), accuracies, label='Accuracy', color='green')\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_ylabel('Accuracy (%)')\n",
    "ax2.set_title('Test Accuracy per Epoch')\n",
    "ax2.legend()\n",
    "ax2.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe014c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(losses)\n",
    "print(len(losses))\n",
    "print(accuracies)\n",
    "print(len(accuracies))\n",
    "print(epoch)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
