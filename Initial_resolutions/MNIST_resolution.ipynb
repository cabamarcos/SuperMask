{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "private_outputs": true,
      "authorship_tag": "ABX9TyNdb/l+mquEVhg0/2rowO1I",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cabamarcos/SuperMask/blob/main/MNIST_Resolution.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EGavdzoVTH4O"
      },
      "outputs": [],
      "source": [
        "# Importing the libraries\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import LearningRateScheduler,ReduceLROnPlateau\n",
        "from tensorflow.keras.datasets import mnist\n",
        "\n",
        "import os\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "print(f\"X_train shape: {X_train.shape}\")\n",
        "print(f\"y_train shape: {y_train.shape}\")\n",
        "print(f\"X_test shape: {X_test.shape}\")\n",
        "print(f\"y_test shape: {y_test.shape}\")"
      ],
      "metadata": {
        "id": "FA6vTjMY1yES"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the labels of the dataset\n",
        "labels = ['0', '1', '2', '3', '4',\n",
        "          '5', '6', '7', '8', '9']\n",
        "\n",
        "# Let's view more images in a grid format\n",
        "# Define the dimensions of the plot grid\n",
        "W_grid = 10\n",
        "L_grid = 10\n",
        "\n",
        "# fig, axes = plt.subplots(L_grid, W_grid)\n",
        "# subplot return the figure object and axes object\n",
        "# we can use the axes object to plot specific figures at various locations\n",
        "\n",
        "fig, axes = plt.subplots(L_grid, W_grid, figsize = (17,17))\n",
        "\n",
        "axes = axes.ravel() # flaten the 15 x 15 matrix into 225 array\n",
        "\n",
        "n_train = len(X_train) # get the length of the train dataset\n",
        "\n",
        "# Select a random number from 0 to n_train\n",
        "for i in np.arange(0, W_grid * L_grid): # create evenly spaces variables\n",
        "\n",
        "    # Select a random number\n",
        "    index = np.random.randint(0, n_train)\n",
        "    # read and display an image with the selected index\n",
        "    axes[i].imshow(X_train[index,1:])\n",
        "    label_index = int(y_train[index])\n",
        "    axes[i].set_title(labels[label_index], fontsize = 8)\n",
        "    axes[i].axis('off')\n",
        "\n",
        "plt.subplots_adjust(hspace=0.4)"
      ],
      "metadata": {
        "id": "3TQHJscM2IQI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classes_name =['0', '1', '2', '3', '4','5', '6', '7', '8', '9']\n",
        "\n",
        "classes, counts = np.unique(y_train, return_counts=True)\n",
        "plt.barh(classes_name, counts)\n",
        "plt.title('Class distribution in training & test')\n",
        "\n",
        "classes, counts = np.unique(y_test, return_counts=True)\n",
        "plt.barh(classes_name, counts)\n"
      ],
      "metadata": {
        "id": "AX4KzzdJ2jCg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Applying Data Augmentation\n",
        "\n",
        "datagen = ImageDataGenerator(rotation_range=10,  zoom_range = 0.1,  width_shift_range=0.1,  height_shift_range=0.1)\n",
        "# datagen.fit(X)"
      ],
      "metadata": {
        "id": "mopojIOr5bm_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Learning rate annealer\n",
        "\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_accuracy',\n",
        "                                patience=3,\n",
        "                                verbose=1,\n",
        "                                factor=0.2,\n",
        "                                min_lr=1e-6)"
      ],
      "metadata": {
        "id": "QqeZLEL15lKY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.models.Sequential([\n",
        "keras.layers.Conv2D(32, kernel_size = 3, activation = 'relu', padding = 'same', input_shape = [28, 28, 1]),\n",
        "keras.layers.BatchNormalization(),\n",
        "keras.layers.Conv2D(64, kernel_size = 3, activation = 'relu', padding = 'same'),\n",
        "keras.layers.MaxPool2D(),\n",
        "keras.layers.Conv2D(32, kernel_size = 3, activation = 'relu', padding = 'same'),\n",
        "keras.layers.BatchNormalization(),\n",
        "keras.layers.Conv2D(64, kernel_size = 3, activation = 'relu', padding = 'same'),\n",
        "keras.layers.MaxPool2D(),\n",
        "keras.layers.Flatten(),\n",
        "keras.layers.Dropout(0.25),\n",
        "keras.layers.Dense(256, activation = 'relu'),\n",
        "keras.layers.Dropout(0.5),\n",
        "keras.layers.Dense(10, activation = 'softmax')])\n",
        "\n",
        "model.compile(loss = 'sparse_categorical_crossentropy', optimizer = 'nadam', metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "PTxDBLqJ5seQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = X_train.reshape((60000, 28, 28, 1))\n"
      ],
      "metadata": {
        "id": "H5UDiBIo6ggW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size = 0.08)\n",
        "history = model.fit_generator(datagen.flow(X_train, y_train, batch_size = 64),\n",
        "                              epochs = 25, validation_data = (X_valid, y_valid), callbacks = [reduce_lr])\n",
        "print(\"Maximum Train Accuracy : {} Maximum Validation Accuracy : {}\".format(max(history.history['accuracy']), max(history.history['val_accuracy'])))\n"
      ],
      "metadata": {
        "id": "eSMV3cpF55Xw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test = X_test.reshape((10000, 28, 28, 1))\n"
      ],
      "metadata": {
        "id": "s3P7iUF8Y7ex"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluar el modelo en el conjunto de prueba\n",
        "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
        "\n",
        "print(\"Test Loss:\", test_loss)\n",
        "print(\"Test Accuracy:\", test_accuracy)\n"
      ],
      "metadata": {
        "id": "EAKBuxnbY5oZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}