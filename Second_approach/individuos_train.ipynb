{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.init as init\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "from ast import Param\n",
    "import json\n",
    "import math\n",
    "\n",
    "from utils.prune import apply_mask\n",
    "from utils.count_improvement import improvements\n",
    "from utils.normalize import normalize_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Verificar si la GPU está disponible y establecer el dispositivo\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
    "        self.fc1 = nn.Linear(128 * 3 * 3, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = x.view(-1, 128 * 3 * 3)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net().to(device)\n",
    "varianzas_net = Net().to(device)\n",
    "individuo = Net().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos el transform para los datos de MNIST\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "# Cargamos el dataset de MNIST\n",
    "train_dataset = datasets.MNIST('./data', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.MNIST('./data', train=False, download=True, transform=transform)\n",
    "\n",
    "# Definimos los DataLoaders para los conjuntos de entrenamiento y prueba\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=4)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1000, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos la función de pérdida para calcular el error\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realizamos el \"entrenamiento\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " --------------------- Individuo 1 --------------------- \n",
      "Epoch: 1, Loss: 0.2702923072680736\n",
      "Accuracy: 0.9594, loss mean: 0.2702923072680736\n"
     ]
    }
   ],
   "source": [
    "# train loop\n",
    "train_loss = []\n",
    "train_loss_mean = []\n",
    "test_accuracies = []\n",
    "n_individuo = 1\n",
    "accuracy_threshold = 0.7\n",
    "best_loss = 100000 # Inicializamos con un valor muy alto para que el primer valor sea mas bajo\n",
    "\n",
    "#Guardo el mejor individuo y la red original que tendrá que ser reestablecida cad epoca\n",
    "best_individo_state_dict = individuo.state_dict()\n",
    "net_state_dict = net.state_dict()\n",
    "\n",
    "#train loop\n",
    "while True:\n",
    "    net.load_state_dict(net_state_dict)\n",
    "    if n_individuo == 1:\n",
    "        epoch = 1\n",
    "        print(f\" --------------------- Individuo {n_individuo} --------------------- \")\n",
    "        while epoch <= 1:\n",
    "            net = apply_mask(net, individuo)\n",
    "            #guardar el estado de la red en un txt en una carpeta\n",
    "            with open(f'pesos/individuo{n_individuo}_epoch{epoch}.txt', 'w') as f:\n",
    "                f.write(str(net.state_dict()))\n",
    "            net.train()\n",
    "            running_loss = 0.0\n",
    "            # Train for 1 epoch\n",
    "            for i, data in enumerate(train_loader, 0):\n",
    "                inputs, labels = data[0].to(device), data[1].to(device)\n",
    "                optimizer.zero_grad()\n",
    "                outputs = net(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                running_loss += loss.item()\n",
    "            train_loss.append(running_loss / len(train_loader))\n",
    "            print(f\"Epoch: {epoch}, Loss: {train_loss[-1]}\")\n",
    "\n",
    "            epoch += 1\n",
    "        net.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for data in test_loader:\n",
    "                images, labels = data[0].to(device), data[1].to(device)\n",
    "                outputs = net(images)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "        accuracy = correct / total\n",
    "        train_loss_mean.append(np.mean(train_loss))\n",
    "        test_accuracies.append(accuracy)\n",
    "        print(f\"Accuracy: {accuracy}, loss mean: {train_loss_mean[-1]}\")\n",
    "        if accuracy > accuracy_threshold:\n",
    "            break\n",
    "    else:\n",
    "        n_individuo += 1\n",
    "        print(f\"Individuo {n_individuo}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.2702923072680736]\n",
      "[0.9594]\n"
     ]
    }
   ],
   "source": [
    "print(train_loss)\n",
    "print(test_accuracies)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
