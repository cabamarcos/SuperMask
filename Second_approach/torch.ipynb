{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ynQ_78kDeHs2"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import copy\n",
        "from ast import Param\n",
        "\n",
        "from utils.prune import prune_weights\n",
        "from utils.count_improvement import improvements"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yC2dq3fNeHs3",
        "outputId": "f25ae62f-1fb0-4f04-ba95-416d32f19c97"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "# Verificar si la GPU está disponible y establecer el dispositivo\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "PpJbsf7NeHs3"
      },
      "outputs": [],
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.fc1 = nn.Linear(784, 256)\n",
        "        self.fc2 = nn.Linear(256, 128)\n",
        "        self.fc3 = nn.Linear(128, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-qzJaokBeHs3"
      },
      "source": [
        "Definimos las redes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "8L94OKmYeHs4"
      },
      "outputs": [],
      "source": [
        "net = Net().to(device)\n",
        "varianzas_net = Net().to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E8W9t_3beHs4"
      },
      "source": [
        "Cargamos los datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JO_Ykr29eHs4",
        "outputId": "16ad4e8d-dace-485a-dcae-f338879a2c3e"
      },
      "outputs": [],
      "source": [
        "# Definimos el transform para los datos de MNIST\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.1307,), (0.3081,))\n",
        "])\n",
        "\n",
        "# Cargamos el dataset de MNIST\n",
        "train_dataset = datasets.MNIST('./data', train=True, download=True, transform=transform)\n",
        "test_dataset = datasets.MNIST('./data', train=False, download=True, transform=transform)\n",
        "\n",
        "# Definimos los DataLoaders para los conjuntos de entrenamiento y prueba\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=1000, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "cWAORhpoeHs4"
      },
      "outputs": [],
      "source": [
        "# Definimos la función de pérdida para calcular el error\n",
        "criterion = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "HTF5fm-peHs4",
        "outputId": "cee40ff8-e105-42b7-a23d-9b5948930430"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1\n",
            "Train loss: 2.3277546030117757\n",
            "Test accuracy: 0.0974\n",
            "Epoch 2\n",
            "Train loss: 2.3238662994746715\n",
            "Test accuracy: 0.087\n",
            "Epoch 3\n",
            "Train loss: 2.3173148293993364\n",
            "Test accuracy: 0.1072\n",
            "Epoch 4\n",
            "Train loss: 2.3382061407255974\n",
            "Test accuracy: 0.0902\n",
            "Epoch 5\n",
            "Train loss: 2.313588749625281\n",
            "Test accuracy: 0.0859\n",
            "Epoch 6\n",
            "Train loss: 2.3150027115970278\n",
            "Test accuracy: 0.1269\n",
            "Epoch 7\n",
            "Train loss: 2.311042940184506\n",
            "Test accuracy: 0.136\n",
            "Epoch 8\n",
            "Train loss: 2.323499440384318\n",
            "Test accuracy: 0.093\n",
            "Epoch 9\n",
            "Train loss: 2.3145109956452585\n",
            "Test accuracy: 0.0922\n",
            "Epoch 10\n",
            "Train loss: 2.3345805678540454\n",
            "Test accuracy: 0.0507\n",
            "Epoch 11\n",
            "Train loss: 2.3541113760933947\n",
            "Test accuracy: 0.1103\n",
            "Epoch 12\n",
            "Train loss: 2.4060182886591344\n",
            "Test accuracy: 0.0903\n",
            "Epoch 13\n",
            "Train loss: 2.5024724436212957\n",
            "Test accuracy: 0.0748\n",
            "Epoch 14\n",
            "Train loss: 2.8167611019951955\n",
            "Test accuracy: 0.1319\n",
            "Epoch 15\n",
            "Train loss: 2.9181126226494305\n",
            "Test accuracy: 0.1329\n",
            "Epoch 16\n",
            "Train loss: 2.5016650632500395\n",
            "Test accuracy: 0.1589\n",
            "Epoch 17\n",
            "Train loss: 2.8058492890807356\n",
            "Test accuracy: 0.1009\n",
            "Epoch 18\n",
            "Train loss: 3.102935525400044\n",
            "Test accuracy: 0.0631\n",
            "Epoch 19\n",
            "Train loss: 2.4852510779651245\n",
            "Test accuracy: 0.1042\n",
            "Epoch 20\n",
            "Train loss: 2.4615860796178075\n",
            "Test accuracy: 0.0896\n",
            "Epoch 21\n",
            "Train loss: 2.5779597017048266\n",
            "Test accuracy: 0.129\n",
            "Epoch 22\n",
            "Train loss: 3.434423821567218\n",
            "Test accuracy: 0.1018\n",
            "Epoch 23\n",
            "Train loss: 5.4459115259174595\n",
            "Test accuracy: 0.1249\n",
            "Epoch 24\n",
            "Train loss: 9.204276655274414\n",
            "Test accuracy: 0.1054\n",
            "Epoch 25\n",
            "Train loss: 16.166549304400935\n",
            "Test accuracy: 0.1143\n",
            "Epoch 26\n",
            "Train loss: 12.603865321511144\n",
            "Test accuracy: 0.0522\n",
            "Epoch 27\n",
            "Train loss: 23.910865659652742\n",
            "Test accuracy: 0.0923\n",
            "Epoch 28\n",
            "Train loss: 45.3718053049116\n",
            "Test accuracy: 0.1388\n",
            "Epoch 29\n",
            "Train loss: 41.256196855736185\n",
            "Test accuracy: 0.1066\n",
            "Epoch 30\n",
            "Train loss: 48.08757605481504\n",
            "Test accuracy: 0.1038\n",
            "Epoch 31\n",
            "Train loss: 32.02076286242715\n",
            "Test accuracy: 0.0909\n",
            "Epoch 32\n",
            "Train loss: 67.54037499580302\n",
            "Test accuracy: 0.1494\n",
            "Epoch 33\n",
            "Train loss: 143.22128321926223\n",
            "Test accuracy: 0.0938\n",
            "Epoch 34\n",
            "Train loss: 239.7612839721159\n",
            "Test accuracy: 0.1241\n",
            "Epoch 35\n",
            "Train loss: 567.7478048816673\n",
            "Test accuracy: 0.0595\n",
            "Epoch 36\n",
            "Train loss: 369.62492110327617\n",
            "Test accuracy: 0.1196\n",
            "Epoch 37\n",
            "Train loss: 801.0473083300885\n",
            "Test accuracy: 0.128\n",
            "Epoch 38\n",
            "Train loss: 2275.5331793095766\n",
            "Test accuracy: 0.0937\n",
            "Epoch 39\n",
            "Train loss: 1809.7934215033233\n",
            "Test accuracy: 0.1074\n",
            "Epoch 40\n",
            "Train loss: 2123.1777248748585\n",
            "Test accuracy: 0.0987\n",
            "Epoch 41\n",
            "Train loss: 2556.345764420434\n",
            "Test accuracy: 0.0897\n",
            "Epoch 42\n",
            "Train loss: 3002.3837479385993\n",
            "Test accuracy: 0.1069\n",
            "Epoch 43\n",
            "Train loss: 2878.5722297066563\n",
            "Test accuracy: 0.0956\n",
            "Epoch 44\n",
            "Train loss: 4511.181800175324\n",
            "Test accuracy: 0.0973\n",
            "Epoch 45\n",
            "Train loss: 13179.947253131662\n",
            "Test accuracy: 0.0656\n",
            "Epoch 46\n",
            "Train loss: 9225.150219362173\n",
            "Test accuracy: 0.1186\n",
            "Epoch 47\n",
            "Train loss: 17607.579080740274\n",
            "Test accuracy: 0.0715\n",
            "Epoch 48\n",
            "Train loss: 35300.06710171242\n",
            "Test accuracy: 0.0901\n",
            "Epoch 49\n",
            "Train loss: 35609.0184360008\n",
            "Test accuracy: 0.058\n",
            "Epoch 50\n",
            "Train loss: 36325.42580415445\n",
            "Test accuracy: 0.1068\n",
            "Epoch 51\n",
            "Train loss: 32362.435950826228\n",
            "Test accuracy: 0.0734\n",
            "Epoch 52\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[7], line 107\u001b[0m\n\u001b[0;32m    105\u001b[0m running_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[0;32m    106\u001b[0m \u001b[38;5;66;03m# Pasamos todas las imagenes de train por la red net\u001b[39;00m\n\u001b[1;32m--> 107\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    108\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mimages\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    110\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutputs_net\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mpruned_net\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\utils\\data\\dataloader.py:701\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    698\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    699\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    700\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 701\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    702\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    703\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    704\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[0;32m    705\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    706\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[0;32m    707\u001b[0m ):\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\utils\\data\\dataloader.py:757\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    755\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    756\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 757\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    758\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    759\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torchvision\\datasets\\mnist.py:146\u001b[0m, in \u001b[0;36mMNIST.__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m    143\u001b[0m img \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mfromarray(img\u001b[38;5;241m.\u001b[39mnumpy(), mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mL\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 146\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    148\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_transform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    149\u001b[0m     target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_transform(target)\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torchvision\\transforms\\transforms.py:95\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[1;34m(self, img)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, img):\n\u001b[0;32m     94\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms:\n\u001b[1;32m---> 95\u001b[0m         img \u001b[38;5;241m=\u001b[39m \u001b[43mt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torchvision\\transforms\\transforms.py:277\u001b[0m, in \u001b[0;36mNormalize.forward\u001b[1;34m(self, tensor)\u001b[0m\n\u001b[0;32m    269\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, tensor: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m    270\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    271\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m    272\u001b[0m \u001b[38;5;124;03m        tensor (Tensor): Tensor image to be normalized.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    275\u001b[0m \u001b[38;5;124;03m        Tensor: Normalized Tensor image.\u001b[39;00m\n\u001b[0;32m    276\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 277\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormalize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torchvision\\transforms\\functional.py:350\u001b[0m, in \u001b[0;36mnormalize\u001b[1;34m(tensor, mean, std, inplace)\u001b[0m\n\u001b[0;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tensor, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[0;32m    348\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimg should be Tensor Image. Got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(tensor)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 350\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF_t\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormalize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmean\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torchvision\\transforms\\_functional_tensor.py:922\u001b[0m, in \u001b[0;36mnormalize\u001b[1;34m(tensor, mean, std, inplace)\u001b[0m\n\u001b[0;32m    920\u001b[0m mean \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mas_tensor(mean, dtype\u001b[38;5;241m=\u001b[39mdtype, device\u001b[38;5;241m=\u001b[39mtensor\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m    921\u001b[0m std \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mas_tensor(std, dtype\u001b[38;5;241m=\u001b[39mdtype, device\u001b[38;5;241m=\u001b[39mtensor\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m--> 922\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43m(\u001b[49m\u001b[43mstd\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43many\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    923\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstd evaluated to zero after conversion to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, leading to division by zero.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    924\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mean\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# train loop\n",
        "train_loss = []\n",
        "test_accuracies = []\n",
        "epoch = 1\n",
        "accuracy_threshold = 0.4\n",
        "\n",
        "\n",
        "while True:\n",
        "    print(f\"Epoch {epoch}\")\n",
        "    if epoch <= 9:\n",
        "\n",
        "        state_dict_red1 = net.state_dict()\n",
        "        state_dict_red2 = varianzas_net.state_dict()\n",
        "\n",
        "        # Crear un nuevo diccionario de estado donde sumamos los pesos\n",
        "        state_dict_suma = {}\n",
        "        for key in state_dict_red1:\n",
        "            if state_dict_red1[key].size() == state_dict_red2[key].size():  # Asegurar que las dimensiones coincidan\n",
        "                # Asegurar que las desviaciones estándar sean positivas para generar el ruido\n",
        "                std_dev = torch.abs(state_dict_red2[key])\n",
        "                \n",
        "                # Generamos los valores aleatorios con una distribución normal usando torch.normal\n",
        "                noise = torch.normal(0, std_dev)  # Media = 0, Desviación estándar = std_dev\n",
        "                \n",
        "                # Crear una máscara para determinar si debemos sumar o restar\n",
        "                mask_negativa = state_dict_red2[key] < 0  # Máscara de valores negativos\n",
        "                \n",
        "                # Aplicar la operación de suma o resta dependiendo de la máscara\n",
        "                state_dict_suma[key] = torch.where(mask_negativa, state_dict_red1[key] - noise, state_dict_red1[key] + noise)\n",
        "            else:\n",
        "                # Si los tamaños no coinciden, copiamos directamente\n",
        "                state_dict_suma[key] = state_dict_red1[key]\n",
        "\n",
        "        # Crear una nueva red o modificar una existente con los pesos sumados\n",
        "        varied_net = Net().to(device)\n",
        "        varied_net.load_state_dict(state_dict_suma)\n",
        "\n",
        "        pruned_net = prune_weights(varied_net)\n",
        "\n",
        "        running_loss = 0.0\n",
        "        # Pasamos todas las imagenes de train por la red net\n",
        "        for images, labels in train_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            outputs_net = pruned_net(images)\n",
        "            loss = criterion(outputs_net, labels)\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        train_loss.append(running_loss / len(train_loader))\n",
        "        print(f\"Train loss: {running_loss / len(train_loader)}\")\n",
        "\n",
        "        # Evaluamos el modelo en el conjunto de test\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        with torch.no_grad():\n",
        "            for images, labels in test_loader:\n",
        "                images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "                outputs_net = pruned_net(images)\n",
        "                _, predicted = torch.max(outputs_net.data, 1)\n",
        "                total += labels.size(0)\n",
        "                correct += (predicted == labels).sum().item()\n",
        "\n",
        "        test_accuracies.append(correct / total)\n",
        "        print(f\"Test accuracy: {correct / total}\")\n",
        "\n",
        "        if correct / total > accuracy_threshold:\n",
        "            break\n",
        "\n",
        "    else:\n",
        "        # Sumamos los pesos de las redes en una red nueva\n",
        "        # Extraer los diccionarios de estado (pesos y biases)\n",
        "        state_dict_red1 = net.state_dict()\n",
        "        state_dict_red2 = varianzas_net.state_dict()\n",
        "\n",
        "        # Crear un nuevo diccionario de estado donde sumamos los pesos\n",
        "        state_dict_suma = {}\n",
        "        for key in state_dict_red1:\n",
        "            if state_dict_red1[key].size() == state_dict_red2[key].size():  # Asegurar que las dimensiones coincidan\n",
        "                # Asegurar que las desviaciones estándar sean positivas para generar el ruido\n",
        "                std_dev = torch.abs(state_dict_red2[key])\n",
        "                \n",
        "                # Generamos los valores aleatorios con una distribución normal usando torch.normal\n",
        "                noise = torch.normal(0, std_dev)  # Media = 0, Desviación estándar = std_dev\n",
        "                \n",
        "                # Crear una máscara para determinar si debemos sumar o restar\n",
        "                mask_negativa = state_dict_red2[key] < 0  # Máscara de valores negativos\n",
        "                \n",
        "                # Aplicar la operación de suma o resta dependiendo de la máscara\n",
        "                state_dict_suma[key] = torch.where(mask_negativa, state_dict_red1[key] - noise, state_dict_red1[key] + noise)\n",
        "            else:\n",
        "                # Si los tamaños no coinciden, copiamos directamente\n",
        "                state_dict_suma[key] = state_dict_red1[key]\n",
        "\n",
        "\n",
        "        # Crear una nueva red o modificar una existente con los pesos sumados\n",
        "        varied_net = Net().to(device)\n",
        "        varied_net.load_state_dict(state_dict_suma)\n",
        "\n",
        "        #print(varied_net.state_dict())\n",
        "\n",
        "        pruned_net = prune_weights(varied_net)\n",
        "\n",
        "        running_loss = 0.0\n",
        "        # Pasamos todas las imagenes de train por la red net\n",
        "        for images, labels in train_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            outputs_net = pruned_net(images)\n",
        "            loss = criterion(outputs_net, labels)\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        train_loss.append(running_loss / len(train_loader))\n",
        "        print(f\"Train loss: {running_loss / len(train_loader)}\")\n",
        "\n",
        "        # Evaluamos el modelo en el conjunto de test\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        with torch.no_grad():\n",
        "            for images, labels in test_loader:\n",
        "                images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "                outputs_net = pruned_net(images)\n",
        "                _, predicted = torch.max(outputs_net.data, 1)\n",
        "                total += labels.size(0)\n",
        "                correct += (predicted == labels).sum().item()\n",
        "\n",
        "        test_accuracies.append(correct / total)\n",
        "        print(f\"Test accuracy: {correct / total}\")\n",
        "\n",
        "        if correct / total > accuracy_threshold:\n",
        "            break\n",
        "\n",
        "        # actualizmos el vector de varianzas\n",
        "        if improvements(train_loss) > 2:## +mejoras que peoras\n",
        "            with torch.no_grad():\n",
        "                for param in varianzas_net.parameters():\n",
        "                    param *= (1/0.82)\n",
        "\n",
        "        elif improvements(train_loss) < 2: ## -mejoras que peoras\n",
        "            with torch.no_grad():\n",
        "                for param in varianzas_net.parameters():\n",
        "                    param *= 0.82\n",
        "        \n",
        "        else:\n",
        "            pass\n",
        "    \n",
        "    epoch += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "iF5e9FeFeHs4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.1589\n"
          ]
        }
      ],
      "source": [
        "print(max(test_accuracies))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[2.3089392459722977, 2.3089258322583586, 2.3089331533354738, 2.3089323369170556, 2.308943989688654, 2.3089327558017234, 2.3089386578053555, 2.308926501507952, 2.308933406496353, 2.331363138867848, 2.3078895896228393, 2.440253779323879, 2.4666561267015013, 2.79058767127584, 3.3400989626008055, 3.010180982953704, 4.811453668801769, 4.418321354556948, 10.217527754525387, 18.82480004296374, 13.772105462007177, 21.99386759556687, 45.70997622475695, 64.74080042239191, 143.58107632309643, 139.96319021294113, 440.29322326920436, 250.359760536568, 480.15460940363056, 1241.5257479864906, 1448.8484698785649, 738.5807276483793, 1341.848469618287, 3422.6838277397887, 5481.837048105594, 5314.774295636077, 7646.559327733542, 8059.600765529218, 10266.443307839985, 6653.3415038021385, 24605.685163746002, 22956.6271446895, 31916.929951942297, 67563.10882945762, 80467.56999600213, 94896.8792810501, 102030.40131929638, 83748.10826725746, 259069.01502531982, 180015.7687566631, 423983.3984874734, 340118.08542110876, 618480.6978611407, 1582377.279717484, 1636815.6735074627, 2655398.175373134, 7814251.787313432, 7783543.070895523, 11631413.538379531, 19396373.5, 9943119.899253732, 19943941.651385926, 14012415.214285715, 22206098.570362475, 41717716.127931766, 51803078.02558635, 148026528.7249467, 111013050.03837954, 170645208.0, 410362239.7953092, 408784889.108742, 759783975.6759062, 858047580.3837953, 686363286.2089552, 1611410906.8827293, 2899107372.759062, 5741172186.88273, 5303786003.923241, 8005585201.671641, 20448131681.159916, 14777676837.117271, 37840946772.0597, 53399841379.343285, 70894754752.6823, 56246690005.970146, 105860321061.66312, 163637433315.6162, 155117233481.6887, 287582566841.0405, 609847607994.678, 511085438133.2196, 1037723085808.7164, 1488088185238.1067, 3212902660187.7017, 3499725452774.891, 4368545459464.1875, 3139239104293.663, 3515198313452.3496, 2918060936578.456, 4310312895546.951, 5516125744182.584, 4780536014878.567, 11449475783393.979, 21462313752685.168, 41436476554111.18, 85130098774950.48, 63879639762223.484, 121166008089086.9, 91093821268509.47, 276533482815627.75, 485157015466411.94, 418409866812479.3, 665260358218365.5, 1221675696257954.0, 2008120888157854.2, 3930232778518432.0, 6512779911652184.0, 4612498430438734.0, 3727285891790590.5, 8836397084029007.0, 1.992181438925973e+16, 1.7584790379740102e+16, 3.3603808832813076e+16, 5.815456033076418e+16, 8.24335848411928e+16, 1.512593478828391e+17, 2.422307341284315e+17, 2.543873286132961e+17, 1.3998216243933214e+17, 1.7262039970822816e+17, 1.679169940904347e+17, 2.019425288459018e+17, 1.5593448390684003e+17, 2.614475725616868e+17, 4.489855054718858e+17, 1.0858257903497887e+18, 1.7923822515984225e+18, 2.464685663518017e+18, 3.1612679750002063e+18, 3.407828470018807e+18, 1.741570449973206e+18, 1.580828756959122e+18, 1.2873203402968868e+18, 3.0563363345306127e+18, 4.850526808460466e+18, 1.0052099686080324e+19, 1.8702642159358644e+19, 4.451199101510635e+19, 6.292007049047772e+19, 7.755702523354803e+19, 8.955721736540281e+19, 5.884904582906571e+19, 2.492629454798745e+19, 2.6960810276899725e+19, 2.763785481006512e+19, 2.402100994020909e+19, 6.1303826489043436e+19, 1.1556140914583218e+20, 2.0427033055466216e+20]\n"
          ]
        }
      ],
      "source": [
        "print(train_loss)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
