{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "from ast import Param\n",
    "\n",
    "from utils.prune import prune_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Verificar si la GPU est√° disponible y establecer el dispositivo\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(784, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos una red y le copiamos los pesos en una lista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict({'fc1.weight': tensor([[-0.0029,  0.0290, -0.0343,  ..., -0.0217, -0.0126,  0.0237],\n",
      "        [-0.0031, -0.0088,  0.0077,  ...,  0.0128, -0.0248, -0.0353],\n",
      "        [ 0.0029, -0.0096, -0.0051,  ..., -0.0028,  0.0191,  0.0127],\n",
      "        ...,\n",
      "        [ 0.0166, -0.0056, -0.0026,  ..., -0.0068, -0.0181,  0.0081],\n",
      "        [ 0.0257, -0.0076,  0.0179,  ..., -0.0251,  0.0145,  0.0244],\n",
      "        [-0.0201,  0.0275, -0.0145,  ...,  0.0045, -0.0289, -0.0089]],\n",
      "       device='cuda:0'), 'fc1.bias': tensor([ 4.2715e-03,  9.3399e-03, -3.0948e-02,  1.4484e-02, -3.1076e-02,\n",
      "        -5.2877e-03,  3.4754e-02,  2.7919e-03,  3.4709e-02,  3.3284e-02,\n",
      "        -2.9984e-02,  1.7072e-02,  2.7890e-02,  3.2782e-02,  1.5063e-02,\n",
      "        -2.5879e-02, -1.5474e-02, -8.1720e-03,  1.1609e-02, -2.2175e-02,\n",
      "         3.0783e-03,  2.5014e-02, -3.2224e-02,  6.8078e-03,  1.9075e-02,\n",
      "         4.2264e-03, -1.4352e-02, -5.5661e-04,  1.1375e-02,  2.0536e-02,\n",
      "        -3.3622e-04, -1.8502e-02, -3.5701e-02, -3.2197e-02, -5.9343e-03,\n",
      "        -6.9686e-03, -3.5905e-03,  8.3821e-03, -1.9427e-02, -4.0004e-04,\n",
      "        -2.3779e-03,  1.2532e-02,  1.6409e-02, -1.1104e-02, -2.7430e-02,\n",
      "         4.7990e-03, -1.4497e-02,  3.2628e-02, -2.0858e-03, -1.0912e-02,\n",
      "         2.4264e-02, -1.7924e-02, -2.3012e-02, -1.3692e-02, -5.8786e-03,\n",
      "        -2.2117e-02, -9.8404e-03, -2.3254e-02,  1.8188e-02,  5.4708e-04,\n",
      "        -6.4969e-04, -3.4090e-02, -2.4552e-02, -1.0992e-02,  4.2543e-03,\n",
      "         3.0318e-02,  2.1918e-02, -1.0326e-02, -3.1616e-02,  7.6351e-03,\n",
      "        -3.0543e-02,  2.9851e-02, -1.3491e-02, -1.0150e-02,  1.4826e-02,\n",
      "         1.7870e-02, -1.5432e-02,  2.3220e-02,  3.0812e-02,  8.5991e-03,\n",
      "         7.3164e-04, -8.7019e-03, -2.5057e-02,  3.1009e-02, -1.7261e-02,\n",
      "         3.0766e-02, -3.0589e-02,  4.8557e-03,  1.1359e-02, -2.2036e-02,\n",
      "        -2.1943e-02,  2.3711e-02, -1.2948e-02, -3.2712e-02,  2.3905e-03,\n",
      "        -2.7792e-02, -2.7974e-02, -1.2836e-02, -1.0519e-02, -3.1469e-02,\n",
      "         2.3646e-02,  2.5049e-02, -2.3876e-02,  5.9414e-03,  2.1577e-02,\n",
      "         2.6811e-02, -3.4674e-02,  1.8485e-02,  5.9020e-03, -2.9578e-02,\n",
      "        -3.1974e-03,  2.3419e-02, -3.3433e-02, -2.9893e-02, -3.0169e-02,\n",
      "         1.3581e-02,  1.4292e-02,  1.4854e-02, -2.7412e-02,  2.5381e-02,\n",
      "         1.0244e-02,  3.1634e-02, -1.4409e-02, -3.4255e-02,  2.6883e-02,\n",
      "         1.4136e-02, -3.3402e-02,  8.1243e-03,  2.5159e-02, -2.3439e-02,\n",
      "        -6.4519e-03, -1.0969e-02, -6.1822e-03,  3.2988e-02,  3.4462e-02,\n",
      "         8.3804e-03,  2.9444e-02,  3.4870e-02,  2.4643e-03, -8.2043e-03,\n",
      "         3.3399e-02, -1.1185e-02, -2.4198e-02,  2.5408e-02, -1.0315e-02,\n",
      "        -6.5071e-03, -2.1196e-02,  2.1457e-03, -1.4318e-02,  2.5605e-02,\n",
      "        -2.0408e-02,  1.8917e-02, -2.9523e-02, -1.2586e-02, -2.3118e-02,\n",
      "        -3.2292e-02, -2.4413e-02,  2.1179e-02,  1.6009e-02,  9.8278e-03,\n",
      "         2.1760e-02, -2.5852e-02,  3.4418e-02, -2.9191e-02, -2.0482e-02,\n",
      "         1.4914e-02, -3.5023e-02, -2.2557e-02,  1.1264e-03, -2.5929e-02,\n",
      "         5.9860e-04,  6.1476e-03, -1.7574e-02, -3.1516e-02, -1.2622e-02,\n",
      "        -1.8129e-02, -1.2413e-02, -1.2244e-02,  3.0007e-02,  3.4738e-02,\n",
      "         1.4404e-02,  7.5437e-03, -6.0007e-04, -1.0061e-02,  5.8356e-03,\n",
      "         3.4178e-02,  2.7458e-02,  2.0063e-02,  6.8535e-03,  1.9544e-02,\n",
      "         3.5170e-02,  4.3183e-03,  2.4894e-02, -2.3324e-02, -1.7690e-02,\n",
      "         7.5210e-03,  6.3926e-03,  3.4220e-02,  2.2402e-02, -7.6912e-04,\n",
      "        -2.6831e-02,  3.0731e-02,  5.2845e-03,  2.0140e-02, -5.5379e-03,\n",
      "        -1.1395e-03,  2.8898e-02,  2.0838e-02, -2.2582e-02,  3.4959e-03,\n",
      "         8.6292e-04, -1.5829e-02, -3.5385e-02, -3.5136e-02, -1.7686e-02,\n",
      "         2.2558e-02,  3.4653e-02, -2.9265e-02,  6.2216e-05,  1.0932e-03,\n",
      "         1.8089e-03,  4.6911e-03,  1.2129e-02, -1.3361e-02,  2.3263e-02,\n",
      "         8.6425e-04, -4.9978e-03, -7.6786e-04,  4.2069e-03, -2.6236e-02,\n",
      "         2.6002e-02, -1.7087e-02, -2.2540e-02,  3.1699e-03, -2.7322e-02,\n",
      "         1.8451e-02,  1.4144e-02, -2.0432e-02,  5.2819e-03,  3.0730e-02,\n",
      "         7.0232e-03,  2.3582e-03,  1.7139e-02, -8.1003e-03,  2.9617e-02,\n",
      "        -1.7133e-02,  5.3295e-03,  2.8186e-02, -2.5238e-02, -1.2148e-02,\n",
      "         3.4807e-02,  4.0032e-03,  6.5800e-03,  7.2792e-04,  1.5210e-02,\n",
      "        -1.0191e-02], device='cuda:0'), 'fc2.weight': tensor([[-0.0570,  0.0222, -0.0232,  ...,  0.0442, -0.0294, -0.0017],\n",
      "        [ 0.0172, -0.0566, -0.0494,  ..., -0.0357, -0.0097, -0.0010],\n",
      "        [ 0.0333, -0.0294,  0.0276,  ...,  0.0050,  0.0418, -0.0363],\n",
      "        ...,\n",
      "        [-0.0171, -0.0010,  0.0410,  ..., -0.0053, -0.0105,  0.0565],\n",
      "        [ 0.0224, -0.0355,  0.0605,  ..., -0.0447,  0.0102, -0.0484],\n",
      "        [ 0.0057,  0.0571,  0.0531,  ..., -0.0413, -0.0314, -0.0343]],\n",
      "       device='cuda:0'), 'fc2.bias': tensor([-0.0556, -0.0019, -0.0226, -0.0162, -0.0110, -0.0107, -0.0620, -0.0214,\n",
      "        -0.0370, -0.0285, -0.0168, -0.0452,  0.0113, -0.0003, -0.0015, -0.0140,\n",
      "         0.0160, -0.0056,  0.0508,  0.0491,  0.0393, -0.0427, -0.0315, -0.0416,\n",
      "        -0.0177,  0.0274, -0.0120, -0.0083, -0.0279,  0.0314,  0.0038,  0.0167,\n",
      "        -0.0355, -0.0064, -0.0423,  0.0456,  0.0149,  0.0561,  0.0429,  0.0274,\n",
      "        -0.0563,  0.0125,  0.0508, -0.0473,  0.0040,  0.0443,  0.0285, -0.0301,\n",
      "         0.0461,  0.0121,  0.0217, -0.0166,  0.0438, -0.0436,  0.0341,  0.0520,\n",
      "         0.0292, -0.0524,  0.0588, -0.0003, -0.0600, -0.0280, -0.0173,  0.0341,\n",
      "        -0.0264, -0.0513, -0.0486,  0.0472, -0.0447, -0.0393, -0.0320, -0.0541,\n",
      "        -0.0215, -0.0482, -0.0182, -0.0232,  0.0487, -0.0289,  0.0494,  0.0163,\n",
      "        -0.0168, -0.0586, -0.0553, -0.0201,  0.0184, -0.0020, -0.0587,  0.0158,\n",
      "        -0.0459, -0.0116, -0.0292,  0.0557, -0.0421, -0.0436,  0.0350,  0.0124,\n",
      "         0.0334, -0.0136, -0.0121, -0.0128,  0.0458,  0.0189,  0.0049,  0.0203,\n",
      "         0.0424, -0.0094,  0.0323,  0.0166,  0.0407, -0.0229, -0.0252,  0.0250,\n",
      "         0.0624, -0.0217, -0.0067,  0.0125, -0.0340, -0.0534, -0.0525, -0.0114,\n",
      "        -0.0144, -0.0462, -0.0073,  0.0528,  0.0097,  0.0528,  0.0280, -0.0098],\n",
      "       device='cuda:0'), 'fc3.weight': tensor([[-0.0196,  0.0812, -0.0208,  ..., -0.0010, -0.0305, -0.0505],\n",
      "        [ 0.0567,  0.0445,  0.0533,  ...,  0.0029, -0.0010, -0.0109],\n",
      "        [-0.0751,  0.0846, -0.0445,  ...,  0.0414, -0.0016, -0.0336],\n",
      "        ...,\n",
      "        [ 0.0406, -0.0586,  0.0522,  ..., -0.0371, -0.0281, -0.0877],\n",
      "        [ 0.0101,  0.0648, -0.0354,  ...,  0.0222, -0.0066,  0.0815],\n",
      "        [ 0.0456, -0.0491,  0.0230,  ..., -0.0365, -0.0636, -0.0744]],\n",
      "       device='cuda:0'), 'fc3.bias': tensor([ 0.0598,  0.0659, -0.0644,  0.0674, -0.0325, -0.0884,  0.0792, -0.0327,\n",
      "        -0.0237,  0.0526], device='cuda:0')})\n"
     ]
    }
   ],
   "source": [
    "net = Net().to(device)\n",
    "varianzas_net = Net().to(device)\n",
    "\n",
    "varianzas = []\n",
    "for param in varianzas_net.parameters():\n",
    "    varianzas.extend(param.data.clone().flatten().tolist())\n",
    "print(varianzas_net.state_dict())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "235146\n",
      "-0.0029386505484580994\n"
     ]
    }
   ],
   "source": [
    "print(len(varianzas))\n",
    "print(varianzas[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of weights: 235146\n"
     ]
    }
   ],
   "source": [
    "# Calculate the number of weights\n",
    "num_weights = sum(p.numel() for p in varianzas_net.parameters() if p.requires_grad)\n",
    "print(f\"Number of weights: {num_weights}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data\\MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9912422/9912422 [00:01<00:00, 9602572.60it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\train-images-idx3-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 28881/28881 [00:00<00:00, 284388.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\train-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1648877/1648877 [00:00<00:00, 2410801.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4542/4542 [00:00<00:00, 4437579.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Definimos el transform para los datos de MNIST\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "# Cargamos el dataset de MNIST\n",
    "train_dataset = datasets.MNIST('./data', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.MNIST('./data', train=False, download=True, transform=transform)\n",
    "\n",
    "# Definimos los DataLoaders para los conjuntos de entrenamiento y prueba\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1000, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos la funci√≥n de p√©rdida para calcular el error\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train loop\n",
    "train_loss = []\n",
    "test_accuracies = []\n",
    "epochs = 10\n",
    "accuracy_threshold = 0.6\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f\"Epoch {epoch + 1}\")\n",
    "    if epoch + 1 == 1:\n",
    "        pruned_net = prune_weights(net)\n",
    "\n",
    "        running_loss = 0.0\n",
    "        # Pasamos todas las imagenes de train por la red net\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            outputs_net = pruned_net(images)\n",
    "            loss = criterion(outputs_net, labels)\n",
    "\n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        train_loss.append(running_loss / len(train_loader))\n",
    "        print(f\"Train loss: {running_loss / len(train_loader)}\")\n",
    "\n",
    "        # Evaluamos el modelo en el conjunto de test\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in test_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "                outputs_net = pruned_net(images)\n",
    "                _, predicted = torch.max(outputs_net.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "        test_accuracies.append(correct / total)\n",
    "        print(f\"Test accuracy: {correct / total}\")\n",
    "\n",
    "        if correct / total > accuracy_threshold:\n",
    "            break\n",
    "    \n",
    "    else:\n",
    "        # Crear una copia de la red neuronal original\n",
    "        varied_net = copy.deepcopy(net)\n",
    "\n",
    "        # Actualizar los pesos de la red neuronal copiada\n",
    "        varied_net.weights = [peso + varianza for peso, varianza in zip(varied_net.weights, varianzas)]\n",
    "\n",
    "        pruned_net = prune_weights(varied_net)\n",
    "\n",
    "        running_loss = 0.0\n",
    "        # Pasamos todas las imagenes de train por la red net\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            outputs_net = pruned_net(images)\n",
    "            loss = criterion(outputs_net, labels)\n",
    "\n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        train_loss.append(running_loss / len(train_loader))\n",
    "        print(f\"Train loss: {running_loss / len(train_loader)}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
