{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "from ast import Param\n",
    "\n",
    "from utils.prune import prune_weights\n",
    "from utils.count_improvement import improvements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Verificar si la GPU est√° disponible y establecer el dispositivo\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(784, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos una red y le copiamos los pesos en una lista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict({'fc1.weight': tensor([[-3.7824e-03, -1.2473e-02, -9.3940e-03,  ...,  2.7885e-02,\n",
      "         -3.3165e-02,  1.5361e-02],\n",
      "        [-7.3810e-03, -1.9430e-02,  3.0847e-02,  ...,  1.4536e-02,\n",
      "         -2.7475e-02,  1.9282e-02],\n",
      "        [-3.3374e-02,  1.4796e-02, -6.4544e-04,  ..., -2.5812e-02,\n",
      "         -1.8412e-02, -3.0038e-02],\n",
      "        ...,\n",
      "        [-2.6505e-05, -1.5706e-02, -5.8061e-03,  ...,  2.8293e-02,\n",
      "         -1.5007e-02,  5.4961e-03],\n",
      "        [-2.0942e-02, -2.4197e-02, -8.9763e-03,  ...,  3.4299e-02,\n",
      "          4.2806e-03, -2.9122e-03],\n",
      "        [-2.6377e-02,  2.3919e-02, -1.2575e-02,  ..., -1.4290e-02,\n",
      "         -2.0268e-02,  2.7221e-02]], device='cuda:0'), 'fc1.bias': tensor([-3.1602e-02, -1.7118e-02,  1.6287e-02, -1.1305e-02,  3.5280e-02,\n",
      "         3.2186e-02, -2.4522e-02, -3.0532e-02,  3.0476e-02, -9.1163e-03,\n",
      "         2.1308e-04, -8.0643e-03, -1.4271e-02, -2.4243e-03,  1.7208e-02,\n",
      "         6.7622e-03, -3.4222e-02,  1.9659e-02, -3.0102e-02,  2.9544e-02,\n",
      "        -9.0373e-03, -3.0693e-03,  1.2780e-02,  8.8341e-03,  4.1856e-03,\n",
      "        -2.5951e-02,  9.5192e-03, -6.9920e-03, -2.2594e-03, -3.5620e-02,\n",
      "        -1.7575e-02,  2.5677e-02, -1.3614e-02, -2.5730e-02,  3.1910e-02,\n",
      "         1.2350e-02, -1.6782e-02,  1.6686e-02,  3.5498e-02, -1.3063e-02,\n",
      "        -3.0964e-02,  2.4913e-02, -2.3749e-02,  2.7265e-02, -2.0025e-02,\n",
      "        -3.6692e-04,  1.7623e-02, -2.8473e-02,  2.9719e-02,  2.0174e-03,\n",
      "         3.4470e-02, -3.4781e-02, -1.5296e-02,  1.9134e-03, -2.9130e-02,\n",
      "        -1.9915e-03, -1.7458e-02, -1.0634e-03,  2.8767e-02,  1.3655e-02,\n",
      "         5.9178e-03,  1.1271e-02, -1.8118e-02,  8.7562e-03,  2.6470e-02,\n",
      "         1.8272e-02,  6.7905e-03,  3.4649e-02, -2.2269e-02,  5.6130e-03,\n",
      "         9.9327e-03,  3.1281e-02,  3.2334e-02, -2.2823e-02,  1.4226e-02,\n",
      "        -3.5141e-02, -2.5527e-02, -5.3809e-03,  8.4645e-03, -1.9634e-02,\n",
      "         1.5498e-02,  9.2912e-03,  2.6093e-02, -5.1431e-03, -2.1365e-02,\n",
      "         2.3826e-02, -1.7012e-02, -2.9963e-02,  2.1302e-02, -3.1065e-02,\n",
      "        -7.2396e-03,  2.9348e-02, -1.5829e-02,  3.2301e-02,  1.5916e-02,\n",
      "         2.0004e-02,  3.2935e-02, -3.4664e-02,  2.4134e-02,  2.3992e-02,\n",
      "        -3.9433e-03, -2.2868e-02, -1.0027e-02,  2.3768e-02, -1.5302e-02,\n",
      "        -2.7077e-02, -3.2445e-02, -1.2789e-02,  5.8097e-03,  2.5411e-02,\n",
      "         3.3837e-03,  5.8818e-03,  3.5423e-03, -5.2228e-03,  1.8757e-02,\n",
      "         9.9942e-03,  2.5869e-02,  3.0275e-02, -1.2069e-02,  2.9085e-02,\n",
      "         6.8890e-03, -8.5458e-06, -2.7582e-02,  2.1984e-02,  7.7595e-03,\n",
      "        -3.5632e-02, -4.1326e-04, -3.2264e-02,  3.5883e-03, -1.5507e-02,\n",
      "        -2.3791e-02, -2.5232e-02,  2.8663e-02,  2.8735e-02, -1.3632e-02,\n",
      "         2.5507e-02,  3.6942e-03, -3.0256e-02, -2.9509e-02,  4.3264e-03,\n",
      "         3.1979e-02, -9.2844e-03,  2.9002e-02,  2.3057e-03, -2.2870e-02,\n",
      "         3.3283e-02, -3.1396e-02, -2.6034e-03,  2.0427e-02,  1.8201e-02,\n",
      "         3.4949e-02,  2.6914e-02,  2.1648e-02,  8.5944e-03,  8.7518e-03,\n",
      "         6.7586e-03,  1.3907e-03,  3.1164e-02, -5.7933e-04, -2.2623e-02,\n",
      "         5.6886e-03, -2.4027e-02, -9.4471e-03, -2.2570e-02, -5.6099e-03,\n",
      "         2.4562e-02,  1.0964e-02,  1.9426e-02, -1.5285e-02, -1.6545e-02,\n",
      "        -3.1383e-02, -1.7245e-02,  6.2088e-03, -2.1322e-02, -2.7100e-02,\n",
      "         2.8217e-02, -2.4584e-02,  1.4578e-02, -2.7434e-02, -9.9429e-03,\n",
      "        -8.8599e-03, -1.0344e-02, -3.3503e-02, -2.3685e-03,  3.5190e-02,\n",
      "        -2.9806e-02, -9.3031e-03, -3.1376e-02, -6.6769e-03, -1.8186e-02,\n",
      "        -2.8514e-03, -1.8510e-02,  1.3705e-02,  1.6906e-02,  1.5770e-02,\n",
      "         1.2173e-02, -2.1100e-02, -2.3885e-02,  2.5865e-02,  2.3645e-02,\n",
      "        -3.1469e-03, -3.0911e-02,  2.6635e-02,  2.2692e-02, -2.6753e-02,\n",
      "         1.0036e-02,  6.0948e-03, -2.0833e-02,  3.4473e-02, -9.6927e-03,\n",
      "         1.7589e-02, -5.0589e-03, -2.9192e-02, -9.8276e-03, -1.2553e-02,\n",
      "        -3.1757e-02,  3.5249e-02,  2.5550e-02, -2.5309e-02,  8.1217e-03,\n",
      "        -3.3860e-02, -8.2524e-03,  1.8263e-02, -6.1158e-03,  1.0541e-02,\n",
      "        -3.0840e-02,  1.0464e-02, -2.8430e-02,  2.8940e-02, -3.0431e-02,\n",
      "        -3.3943e-02,  2.3802e-03,  1.0554e-02, -4.6705e-03, -7.9172e-03,\n",
      "        -5.9187e-03,  2.7591e-02,  2.1778e-02, -2.6644e-02,  3.3983e-03,\n",
      "         3.0877e-02,  1.4843e-02,  1.8289e-02, -2.3239e-03, -5.6404e-03,\n",
      "         7.6154e-03, -2.9406e-02,  3.4172e-04, -1.4459e-02, -3.2863e-02,\n",
      "        -3.1848e-02,  3.3376e-02, -5.2896e-03, -1.6912e-02, -1.1584e-02,\n",
      "        -3.5304e-02], device='cuda:0'), 'fc2.weight': tensor([[-0.0200,  0.0319, -0.0482,  ..., -0.0623, -0.0055,  0.0294],\n",
      "        [-0.0317, -0.0276, -0.0236,  ...,  0.0258, -0.0570, -0.0046],\n",
      "        [ 0.0589, -0.0516, -0.0251,  ..., -0.0467, -0.0622,  0.0466],\n",
      "        ...,\n",
      "        [-0.0551,  0.0109, -0.0430,  ..., -0.0142, -0.0424, -0.0135],\n",
      "        [-0.0623, -0.0347,  0.0265,  ..., -0.0050,  0.0246, -0.0045],\n",
      "        [-0.0428,  0.0327,  0.0369,  ...,  0.0006,  0.0489, -0.0429]],\n",
      "       device='cuda:0'), 'fc2.bias': tensor([-9.4191e-03, -2.5917e-02, -4.4204e-02,  3.0959e-02,  6.0072e-02,\n",
      "         1.5590e-03, -2.7264e-02,  8.0323e-03,  1.4921e-02, -4.6282e-02,\n",
      "        -4.4805e-02, -1.2912e-02,  1.0002e-02,  5.3406e-02,  5.7867e-02,\n",
      "         4.4124e-02,  8.1589e-03, -6.0979e-02,  1.0478e-02,  1.3281e-02,\n",
      "        -4.5348e-02, -3.9507e-02,  1.4466e-02,  3.5075e-02,  2.1781e-02,\n",
      "        -1.8689e-02, -3.9591e-02,  3.4249e-02,  1.9683e-02, -3.4177e-02,\n",
      "        -3.2760e-02,  4.0914e-02, -8.4817e-05,  5.9964e-03, -3.0530e-02,\n",
      "         6.9358e-03,  8.3819e-04, -5.8390e-02, -5.0716e-02,  4.4512e-03,\n",
      "        -3.0370e-02,  6.1033e-02,  3.4206e-02,  5.5974e-02, -1.9559e-02,\n",
      "        -3.3203e-02, -1.3874e-02,  4.1462e-02,  2.4596e-02,  5.9645e-02,\n",
      "        -1.7856e-02, -6.0501e-02,  2.3696e-02,  6.4431e-03, -2.7491e-02,\n",
      "        -3.3253e-02,  2.0626e-02,  1.8352e-02,  3.0046e-02, -2.6073e-03,\n",
      "         1.1756e-02,  3.0173e-02,  6.0564e-03, -2.1553e-02,  2.0965e-02,\n",
      "        -1.9521e-02, -1.5208e-02,  5.0588e-02,  4.9136e-02, -3.7985e-02,\n",
      "         2.4999e-02, -2.0451e-02,  3.7941e-02,  1.5077e-02,  5.5812e-02,\n",
      "        -9.3739e-03,  5.4331e-02, -1.6623e-02,  4.9656e-03,  1.0549e-02,\n",
      "         5.1781e-02, -3.4205e-02, -3.3460e-02, -5.7054e-02,  2.3731e-02,\n",
      "        -5.5903e-02,  3.2842e-03,  8.3923e-03, -2.8703e-02,  5.6497e-03,\n",
      "         3.2433e-02,  3.0339e-02, -1.8018e-02,  4.4032e-03,  2.1787e-02,\n",
      "         4.8992e-02, -1.4386e-03, -2.4008e-02,  2.8963e-02,  5.8826e-02,\n",
      "         4.0006e-02,  2.5246e-02,  1.6767e-02,  1.3622e-03, -1.5649e-03,\n",
      "         5.9547e-03,  1.6931e-02,  1.6317e-02,  5.2752e-02, -6.0723e-03,\n",
      "         3.0938e-02,  1.0265e-02, -4.8550e-02, -2.0696e-02, -4.8818e-02,\n",
      "        -4.6793e-04,  1.7002e-02, -2.9686e-02, -6.1181e-02, -5.2385e-02,\n",
      "         4.6610e-02, -3.8874e-03,  5.9064e-02,  4.2803e-02, -1.9203e-02,\n",
      "        -9.5888e-03,  2.7851e-02,  4.3337e-02], device='cuda:0'), 'fc3.weight': tensor([[-0.0382, -0.0694,  0.0195,  ...,  0.0192,  0.0163,  0.0497],\n",
      "        [-0.0624, -0.0834, -0.0221,  ...,  0.0288, -0.0155,  0.0353],\n",
      "        [ 0.0200,  0.0140, -0.0001,  ...,  0.0234,  0.0362, -0.0195],\n",
      "        ...,\n",
      "        [-0.0021, -0.0458, -0.0672,  ...,  0.0112, -0.0082,  0.0595],\n",
      "        [ 0.0606, -0.0605, -0.0814,  ...,  0.0483,  0.0071, -0.0318],\n",
      "        [-0.0198, -0.0334,  0.0369,  ..., -0.0749,  0.0025,  0.0018]],\n",
      "       device='cuda:0'), 'fc3.bias': tensor([-0.0608,  0.0537, -0.0299,  0.0664, -0.0417, -0.0563, -0.0687,  0.0850,\n",
      "        -0.0820, -0.0156], device='cuda:0')})\n"
     ]
    }
   ],
   "source": [
    "net = Net().to(device)\n",
    "varianzas_net = Net().to(device)\n",
    "\n",
    "varianzas = []\n",
    "for param in varianzas_net.parameters():\n",
    "    varianzas.extend(param.data.clone().flatten().tolist())\n",
    "print(varianzas_net.state_dict())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "235146\n",
      "-0.003782421350479126\n"
     ]
    }
   ],
   "source": [
    "print(len(varianzas))\n",
    "print(varianzas[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of weights: 235146\n"
     ]
    }
   ],
   "source": [
    "# Calculate the number of weights\n",
    "num_weights = sum(p.numel() for p in varianzas_net.parameters() if p.requires_grad)\n",
    "print(f\"Number of weights: {num_weights}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos el transform para los datos de MNIST\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "# Cargamos el dataset de MNIST\n",
    "train_dataset = datasets.MNIST('./data', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.MNIST('./data', train=False, download=True, transform=transform)\n",
    "\n",
    "# Definimos los DataLoaders para los conjuntos de entrenamiento y prueba\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1000, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos la funci√≥n de p√©rdida para calcular el error\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "Train loss: 2.308339726950314\n",
      "Test accuracy: 0.0924\n",
      "Epoch 2\n",
      "OrderedDict({'fc1.weight': tensor([[-0.0346,  0.0000,  0.0287,  ...,  0.0287,  0.0000,  0.0000],\n",
      "        [ 0.0265,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000, -0.0345,  ...,  0.0000,  0.0333,  0.0000],\n",
      "        ...,\n",
      "        [-0.0301,  0.0000,  0.0000,  ...,  0.0000,  0.0000, -0.0299],\n",
      "        [-0.0321,  0.0000,  0.0000,  ...,  0.0000,  0.0297,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0'), 'fc1.bias': tensor([-1.0868e-02, -5.9395e-03, -2.5255e-02, -6.9755e-03, -2.5891e-02,\n",
      "         4.1298e-03,  1.4969e-02, -8.4799e-03, -1.0652e-02,  3.3648e-02,\n",
      "         1.7382e-02,  2.1708e-02,  1.1924e-02, -1.4142e-02, -2.9194e-03,\n",
      "         2.2122e-02,  1.5926e-02,  7.5681e-03,  2.5220e-05, -2.0818e-02,\n",
      "        -3.0350e-03, -3.1327e-02, -1.5511e-03,  1.2087e-02,  2.7704e-02,\n",
      "        -1.3782e-02, -3.4459e-02,  2.0656e-02, -3.1582e-02,  2.1182e-02,\n",
      "         1.0652e-02,  1.2198e-02,  2.4334e-02, -2.9982e-02, -3.5023e-02,\n",
      "        -3.0259e-02,  1.4693e-02,  1.7856e-02,  1.3606e-02, -3.2377e-02,\n",
      "         2.2182e-02,  1.0795e-02, -2.7106e-02,  1.6569e-02,  2.1490e-02,\n",
      "         2.6935e-02, -3.3763e-02,  3.1031e-02, -1.5672e-02, -1.8419e-02,\n",
      "         2.7500e-02, -2.5501e-02, -2.7811e-02,  3.1733e-02, -1.2646e-02,\n",
      "         2.3861e-02,  2.4408e-02,  1.6704e-02,  1.8171e-02,  3.1489e-02,\n",
      "         1.9330e-02, -3.1405e-02,  1.2452e-02,  1.4022e-02, -3.4676e-02,\n",
      "        -2.7369e-02,  2.7255e-02,  2.0146e-02, -2.7486e-02, -4.5679e-03,\n",
      "        -2.0807e-02,  1.8368e-02,  1.6832e-02, -1.5661e-02,  1.8277e-04,\n",
      "         1.4005e-02, -1.2626e-02,  9.8972e-03, -3.5431e-02,  6.9809e-03,\n",
      "         6.1352e-03, -2.6294e-03, -3.1017e-02,  2.6243e-02,  2.7201e-02,\n",
      "        -4.2901e-03,  1.9301e-02, -2.1207e-02, -3.3671e-02, -3.1217e-02,\n",
      "         6.5066e-03,  2.7173e-02,  3.1513e-02,  8.3830e-05, -1.5641e-02,\n",
      "        -3.0109e-02,  1.6290e-02, -4.8084e-03,  2.8899e-02, -4.4025e-03,\n",
      "        -1.3338e-02, -2.2227e-02,  1.6400e-03, -9.9538e-03, -2.7384e-02,\n",
      "         8.8400e-04, -1.5965e-02,  1.8518e-02,  2.1814e-02,  2.7947e-02,\n",
      "         2.9207e-02,  1.7507e-02,  1.1051e-02,  1.6562e-02, -3.3521e-02,\n",
      "         1.2367e-02,  6.3117e-03, -3.0777e-02, -1.0119e-02, -3.2875e-02,\n",
      "         1.9876e-02,  2.5285e-02, -1.7967e-03, -8.1559e-03,  2.7394e-02,\n",
      "        -2.3252e-02, -6.5550e-03, -2.6216e-02, -2.0705e-02,  2.8556e-02,\n",
      "         1.6800e-02,  1.5743e-03,  2.8316e-02,  1.5006e-02,  1.1886e-03,\n",
      "        -1.5562e-02, -3.0674e-02, -5.8166e-03,  1.3629e-03,  2.5214e-03,\n",
      "         1.5544e-02,  3.4694e-03,  2.1140e-02,  2.7473e-03, -3.0004e-02,\n",
      "         1.1869e-02, -1.1763e-02,  7.3276e-03, -2.8593e-02,  3.3902e-02,\n",
      "        -6.4871e-03, -2.1743e-02,  2.2879e-02, -1.1630e-02, -2.2267e-02,\n",
      "        -3.2318e-03,  3.3676e-03, -1.2853e-02,  1.8242e-02,  3.0522e-02,\n",
      "        -1.0736e-03,  3.3132e-02, -2.7127e-02,  3.1748e-02,  2.3755e-02,\n",
      "         1.6898e-02,  2.5242e-02,  6.4221e-03, -6.0177e-03, -1.1989e-02,\n",
      "        -3.1861e-02, -3.1566e-02, -3.5193e-02, -2.1316e-02, -1.5913e-02,\n",
      "         2.2527e-02, -3.5243e-02,  2.7659e-03,  3.5319e-02, -2.1937e-02,\n",
      "        -6.7410e-03, -2.8867e-02, -6.6908e-03,  1.6601e-02, -2.8745e-02,\n",
      "        -1.1122e-02, -1.9665e-02, -8.5236e-03,  3.1531e-02, -1.8995e-02,\n",
      "         2.4836e-02, -1.0712e-02,  1.5861e-02, -2.7326e-02,  6.4606e-03,\n",
      "         2.4985e-02, -3.6411e-03, -3.5472e-02, -3.4772e-02,  1.0534e-02,\n",
      "         1.9675e-02,  1.4745e-02, -7.7223e-03, -2.0280e-02, -1.5342e-02,\n",
      "        -2.9629e-02, -2.9189e-02,  5.0050e-03,  2.2354e-02,  3.3478e-02,\n",
      "        -9.7301e-03,  2.3630e-02,  1.5672e-03,  1.4516e-02,  1.6460e-02,\n",
      "         8.1221e-03, -1.5814e-03, -1.7094e-02, -8.9703e-03,  3.3870e-02,\n",
      "         3.0677e-02,  1.2907e-02, -1.1274e-02, -1.4837e-03,  1.6462e-02,\n",
      "         3.5444e-02, -3.0789e-02, -3.8700e-03,  2.4096e-02, -9.6586e-03,\n",
      "        -9.2596e-03, -1.3157e-02, -3.0595e-02,  3.1801e-02,  2.1921e-02,\n",
      "         1.7284e-02,  1.3197e-02, -2.4958e-02, -6.6629e-04, -1.1050e-03,\n",
      "        -1.6129e-02, -7.9483e-04,  1.0822e-02, -1.4541e-02,  5.4773e-03,\n",
      "        -1.8167e-02,  2.0274e-02, -3.0704e-02,  3.4098e-02,  3.4127e-02,\n",
      "         1.3918e-02,  2.1365e-02, -1.6390e-02, -3.1461e-02,  1.6880e-02,\n",
      "        -2.5817e-02], device='cuda:0'), 'fc2.weight': tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000, -0.0610],\n",
      "        [ 0.0000, -0.0451, -0.0497,  ...,  0.0612,  0.0000, -0.0475],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000, -0.0459],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0561,  0.0471,  0.0000],\n",
      "        [ 0.0000, -0.0477,  0.0000,  ...,  0.0547,  0.0000,  0.0588],\n",
      "        [ 0.0000,  0.0000,  0.0481,  ...,  0.0000,  0.0476,  0.0000]],\n",
      "       device='cuda:0'), 'fc2.bias': tensor([ 0.0377, -0.0600, -0.0549, -0.0076,  0.0439, -0.0386,  0.0246, -0.0511,\n",
      "        -0.0316,  0.0454, -0.0252,  0.0231,  0.0026,  0.0129, -0.0621, -0.0044,\n",
      "        -0.0324,  0.0036,  0.0502,  0.0513, -0.0481, -0.0118,  0.0233, -0.0561,\n",
      "        -0.0295,  0.0215,  0.0150, -0.0039, -0.0086, -0.0283,  0.0503, -0.0219,\n",
      "        -0.0110,  0.0011,  0.0468,  0.0343, -0.0310,  0.0098, -0.0293,  0.0178,\n",
      "         0.0592, -0.0253,  0.0372, -0.0323, -0.0176, -0.0210,  0.0173, -0.0494,\n",
      "        -0.0393,  0.0171, -0.0020, -0.0312,  0.0233,  0.0345,  0.0056,  0.0083,\n",
      "        -0.0521,  0.0446,  0.0414,  0.0108,  0.0326, -0.0088,  0.0514,  0.0603,\n",
      "         0.0238,  0.0614,  0.0622,  0.0398, -0.0165,  0.0178,  0.0152, -0.0082,\n",
      "        -0.0239,  0.0121, -0.0181, -0.0115,  0.0018, -0.0059, -0.0413, -0.0466,\n",
      "         0.0445,  0.0031,  0.0471,  0.0540, -0.0260,  0.0171, -0.0506, -0.0432,\n",
      "         0.0137,  0.0046, -0.0224,  0.0416,  0.0561,  0.0144,  0.0080, -0.0450,\n",
      "        -0.0012,  0.0494,  0.0020,  0.0378,  0.0587,  0.0066,  0.0130, -0.0356,\n",
      "        -0.0397,  0.0186,  0.0407, -0.0278, -0.0148, -0.0551,  0.0547,  0.0386,\n",
      "        -0.0143,  0.0579,  0.0188,  0.0433,  0.0296,  0.0219,  0.0417, -0.0053,\n",
      "         0.0365,  0.0129,  0.0558, -0.0451, -0.0152,  0.0232, -0.0341,  0.0469],\n",
      "       device='cuda:0'), 'fc3.weight': tensor([[ 0.0000,  0.0000, -0.0818,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0705,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000, -0.0852,  0.0000],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0670,  0.0000,  ..., -0.0716,  0.0797,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0695,  0.0000,  0.0765],\n",
      "        [-0.0633,  0.0000, -0.0678,  ...,  0.0000,  0.0000,  0.0849]],\n",
      "       device='cuda:0'), 'fc3.bias': tensor([ 0.0312,  0.0081,  0.0121, -0.0028, -0.0332, -0.0566, -0.0438,  0.0196,\n",
      "        -0.0658,  0.0469], device='cuda:0')})\n",
      "OrderedDict({'fc1.weight': tensor([[-0.0384, -0.0038,  0.0249,  ...,  0.0249, -0.0038, -0.0038],\n",
      "        [ 0.0228, -0.0038, -0.0038,  ..., -0.0038, -0.0038, -0.0038],\n",
      "        [-0.0038, -0.0038, -0.0383,  ..., -0.0038,  0.0295, -0.0038],\n",
      "        ...,\n",
      "        [-0.0339, -0.0038, -0.0038,  ..., -0.0038, -0.0038, -0.0337],\n",
      "        [-0.0359, -0.0038, -0.0038,  ..., -0.0038,  0.0259, -0.0038],\n",
      "        [-0.0038, -0.0038, -0.0038,  ..., -0.0038, -0.0038, -0.0038]],\n",
      "       device='cuda:0'), 'fc1.bias': tensor([-2.3341e-02, -1.8413e-02, -3.7728e-02, -1.9449e-02, -3.8364e-02,\n",
      "        -8.3433e-03,  2.4962e-03, -2.0953e-02, -2.3125e-02,  2.1175e-02,\n",
      "         4.9090e-03,  9.2352e-03, -5.4953e-04, -2.6615e-02, -1.5392e-02,\n",
      "         9.6488e-03,  3.4534e-03, -4.9050e-03, -1.2448e-02, -3.3291e-02,\n",
      "        -1.5508e-02, -4.3800e-02, -1.4024e-02, -3.8602e-04,  1.5231e-02,\n",
      "        -2.6255e-02, -4.6932e-02,  8.1830e-03, -4.4055e-02,  8.7087e-03,\n",
      "        -1.8215e-03, -2.7509e-04,  1.1861e-02, -4.2456e-02, -4.7496e-02,\n",
      "        -4.2732e-02,  2.2200e-03,  5.3829e-03,  1.1328e-03, -4.4850e-02,\n",
      "         9.7088e-03, -1.6776e-03, -3.9579e-02,  4.0957e-03,  9.0165e-03,\n",
      "         1.4462e-02, -4.6236e-02,  1.8558e-02, -2.8145e-02, -3.0893e-02,\n",
      "         1.5027e-02, -3.7974e-02, -4.0284e-02,  1.9260e-02, -2.5119e-02,\n",
      "         1.1388e-02,  1.1935e-02,  4.2309e-03,  5.6983e-03,  1.9016e-02,\n",
      "         6.8568e-03, -4.3878e-02, -2.1415e-05,  1.5485e-03, -4.7149e-02,\n",
      "        -3.9843e-02,  1.4782e-02,  7.6731e-03, -3.9959e-02, -1.7041e-02,\n",
      "        -3.3280e-02,  5.8946e-03,  4.3588e-03, -2.8134e-02, -1.2290e-02,\n",
      "         1.5322e-03, -2.5099e-02, -2.5758e-03, -4.7904e-02, -5.4922e-03,\n",
      "        -6.3378e-03, -1.5102e-02, -4.3490e-02,  1.3770e-02,  1.4728e-02,\n",
      "        -1.6763e-02,  6.8278e-03, -3.3680e-02, -4.6144e-02, -4.3690e-02,\n",
      "        -5.9664e-03,  1.4700e-02,  1.9040e-02, -1.2389e-02, -2.8114e-02,\n",
      "        -4.2582e-02,  3.8166e-03, -1.7281e-02,  1.6425e-02, -1.6876e-02,\n",
      "        -2.5811e-02, -3.4700e-02, -1.0833e-02, -2.2427e-02, -3.9857e-02,\n",
      "        -1.1589e-02, -2.8438e-02,  6.0454e-03,  9.3408e-03,  1.5474e-02,\n",
      "         1.6734e-02,  5.0340e-03, -1.4220e-03,  4.0889e-03, -4.5994e-02,\n",
      "        -1.0590e-04, -6.1614e-03, -4.3250e-02, -2.2592e-02, -4.5348e-02,\n",
      "         7.4034e-03,  1.2812e-02, -1.4270e-02, -2.0629e-02,  1.4921e-02,\n",
      "        -3.5725e-02, -1.9028e-02, -3.8689e-02, -3.3178e-02,  1.6083e-02,\n",
      "         4.3271e-03, -1.0899e-02,  1.5842e-02,  2.5326e-03, -1.1284e-02,\n",
      "        -2.8035e-02, -4.3147e-02, -1.8290e-02, -1.1110e-02, -9.9516e-03,\n",
      "         3.0708e-03, -9.0037e-03,  8.6671e-03, -9.7257e-03, -4.2477e-02,\n",
      "        -6.0355e-04, -2.4236e-02, -5.1454e-03, -4.1066e-02,  2.1429e-02,\n",
      "        -1.8960e-02, -3.4216e-02,  1.0406e-02, -2.4103e-02, -3.4740e-02,\n",
      "        -1.5705e-02, -9.1055e-03, -2.5326e-02,  5.7688e-03,  1.8049e-02,\n",
      "        -1.3547e-02,  2.0659e-02, -3.9600e-02,  1.9275e-02,  1.1282e-02,\n",
      "         4.4253e-03,  1.2769e-02, -6.0510e-03, -1.8491e-02, -2.4462e-02,\n",
      "        -4.4334e-02, -4.4039e-02, -4.7666e-02, -3.3789e-02, -2.8386e-02,\n",
      "         1.0054e-02, -4.7716e-02, -9.7072e-03,  2.2846e-02, -3.4410e-02,\n",
      "        -1.9214e-02, -4.1340e-02, -1.9164e-02,  4.1279e-03, -4.1218e-02,\n",
      "        -2.3595e-02, -3.2138e-02, -2.0997e-02,  1.9058e-02, -3.1468e-02,\n",
      "         1.2363e-02, -2.3185e-02,  3.3876e-03, -3.9799e-02, -6.0124e-03,\n",
      "         1.2512e-02, -1.6114e-02, -4.7945e-02, -4.7245e-02, -1.9391e-03,\n",
      "         7.2023e-03,  2.2720e-03, -2.0195e-02, -3.2753e-02, -2.7815e-02,\n",
      "        -4.2102e-02, -4.1662e-02, -7.4681e-03,  9.8807e-03,  2.1005e-02,\n",
      "        -2.2203e-02,  1.1157e-02, -1.0906e-02,  2.0431e-03,  3.9869e-03,\n",
      "        -4.3510e-03, -1.4054e-02, -2.9567e-02, -2.1443e-02,  2.1397e-02,\n",
      "         1.8204e-02,  4.3352e-04, -2.3748e-02, -1.3957e-02,  3.9894e-03,\n",
      "         2.2971e-02, -4.3263e-02, -1.6343e-02,  1.1623e-02, -2.2132e-02,\n",
      "        -2.1733e-02, -2.5630e-02, -4.3068e-02,  1.9328e-02,  9.4482e-03,\n",
      "         4.8105e-03,  7.2381e-04, -3.7432e-02, -1.3139e-02, -1.3578e-02,\n",
      "        -2.8602e-02, -1.3268e-02, -1.6510e-03, -2.7014e-02, -6.9958e-03,\n",
      "        -3.0640e-02,  7.8009e-03, -4.3177e-02,  2.1625e-02,  2.1654e-02,\n",
      "         1.4446e-03,  8.8917e-03, -2.8864e-02, -4.3934e-02,  4.4070e-03,\n",
      "        -3.8290e-02], device='cuda:0'), 'fc2.weight': tensor([[-0.0094, -0.0094, -0.0094,  ..., -0.0094, -0.0094, -0.0704],\n",
      "        [-0.0094, -0.0545, -0.0591,  ...,  0.0518, -0.0094, -0.0569],\n",
      "        [-0.0094, -0.0094, -0.0094,  ..., -0.0094, -0.0094, -0.0553],\n",
      "        ...,\n",
      "        [-0.0094, -0.0094, -0.0094,  ...,  0.0467,  0.0377, -0.0094],\n",
      "        [-0.0094, -0.0570, -0.0094,  ...,  0.0453, -0.0094,  0.0494],\n",
      "        [-0.0094, -0.0094,  0.0387,  ..., -0.0094,  0.0382, -0.0094]],\n",
      "       device='cuda:0'), 'fc2.bias': tensor([ 0.0345, -0.0632, -0.0581, -0.0109,  0.0407, -0.0419,  0.0214, -0.0544,\n",
      "        -0.0348,  0.0422, -0.0285,  0.0199, -0.0006,  0.0097, -0.0653, -0.0076,\n",
      "        -0.0357,  0.0003,  0.0469,  0.0480, -0.0514, -0.0150,  0.0201, -0.0594,\n",
      "        -0.0328,  0.0183,  0.0117, -0.0072, -0.0118, -0.0315,  0.0471, -0.0251,\n",
      "        -0.0142, -0.0022,  0.0436,  0.0311, -0.0342,  0.0066, -0.0326,  0.0145,\n",
      "         0.0560, -0.0286,  0.0339, -0.0355, -0.0208, -0.0242,  0.0141, -0.0527,\n",
      "        -0.0425,  0.0138, -0.0053, -0.0345,  0.0201,  0.0312,  0.0023,  0.0051,\n",
      "        -0.0554,  0.0413,  0.0381,  0.0076,  0.0293, -0.0120,  0.0482,  0.0570,\n",
      "         0.0205,  0.0581,  0.0590,  0.0366, -0.0197,  0.0145,  0.0119, -0.0114,\n",
      "        -0.0271,  0.0089, -0.0213, -0.0147, -0.0014, -0.0091, -0.0446, -0.0499,\n",
      "         0.0413, -0.0001,  0.0438,  0.0507, -0.0293,  0.0138, -0.0538, -0.0464,\n",
      "         0.0104,  0.0014, -0.0257,  0.0383,  0.0529,  0.0111,  0.0047, -0.0482,\n",
      "        -0.0044,  0.0461, -0.0012,  0.0346,  0.0554,  0.0034,  0.0098, -0.0388,\n",
      "        -0.0430,  0.0154,  0.0375, -0.0310, -0.0180, -0.0583,  0.0514,  0.0354,\n",
      "        -0.0175,  0.0546,  0.0156,  0.0401,  0.0263,  0.0186,  0.0384, -0.0086,\n",
      "         0.0333,  0.0097,  0.0526, -0.0484, -0.0184,  0.0200, -0.0373,  0.0437],\n",
      "       device='cuda:0'), 'fc3.weight': tensor([[ 0.0151,  0.0151, -0.0667,  ...,  0.0151,  0.0151,  0.0151],\n",
      "        [ 0.0151,  0.0151,  0.0856,  ...,  0.0151,  0.0151,  0.0151],\n",
      "        [ 0.0151,  0.0151,  0.0151,  ...,  0.0151, -0.0701,  0.0151],\n",
      "        ...,\n",
      "        [ 0.0151,  0.0821,  0.0151,  ..., -0.0565,  0.0948,  0.0151],\n",
      "        [ 0.0151,  0.0151,  0.0151,  ...,  0.0846,  0.0151,  0.0916],\n",
      "        [-0.0482,  0.0151, -0.0527,  ...,  0.0151,  0.0151,  0.1000]],\n",
      "       device='cuda:0'), 'fc3.bias': tensor([ 0.0322,  0.0090,  0.0131, -0.0019, -0.0323, -0.0556, -0.0428,  0.0206,\n",
      "        -0.0649,  0.0479], device='cuda:0')})\n",
      "Train loss: 2.3048017965450978\n",
      "Test accuracy: 0.0739\n",
      "Epoch 3\n",
      "OrderedDict({'fc1.weight': tensor([[-0.0346,  0.0000,  0.0287,  ...,  0.0287,  0.0000,  0.0000],\n",
      "        [ 0.0265,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000, -0.0345,  ...,  0.0000,  0.0333,  0.0000],\n",
      "        ...,\n",
      "        [-0.0301,  0.0000,  0.0000,  ...,  0.0000,  0.0000, -0.0299],\n",
      "        [-0.0321,  0.0000,  0.0000,  ...,  0.0000,  0.0297,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0'), 'fc1.bias': tensor([-1.0868e-02, -5.9395e-03, -2.5255e-02, -6.9755e-03, -2.5891e-02,\n",
      "         4.1298e-03,  1.4969e-02, -8.4799e-03, -1.0652e-02,  3.3648e-02,\n",
      "         1.7382e-02,  2.1708e-02,  1.1924e-02, -1.4142e-02, -2.9194e-03,\n",
      "         2.2122e-02,  1.5926e-02,  7.5681e-03,  2.5220e-05, -2.0818e-02,\n",
      "        -3.0350e-03, -3.1327e-02, -1.5511e-03,  1.2087e-02,  2.7704e-02,\n",
      "        -1.3782e-02, -3.4459e-02,  2.0656e-02, -3.1582e-02,  2.1182e-02,\n",
      "         1.0652e-02,  1.2198e-02,  2.4334e-02, -2.9982e-02, -3.5023e-02,\n",
      "        -3.0259e-02,  1.4693e-02,  1.7856e-02,  1.3606e-02, -3.2377e-02,\n",
      "         2.2182e-02,  1.0795e-02, -2.7106e-02,  1.6569e-02,  2.1490e-02,\n",
      "         2.6935e-02, -3.3763e-02,  3.1031e-02, -1.5672e-02, -1.8419e-02,\n",
      "         2.7500e-02, -2.5501e-02, -2.7811e-02,  3.1733e-02, -1.2646e-02,\n",
      "         2.3861e-02,  2.4408e-02,  1.6704e-02,  1.8171e-02,  3.1489e-02,\n",
      "         1.9330e-02, -3.1405e-02,  1.2452e-02,  1.4022e-02, -3.4676e-02,\n",
      "        -2.7369e-02,  2.7255e-02,  2.0146e-02, -2.7486e-02, -4.5679e-03,\n",
      "        -2.0807e-02,  1.8368e-02,  1.6832e-02, -1.5661e-02,  1.8277e-04,\n",
      "         1.4005e-02, -1.2626e-02,  9.8972e-03, -3.5431e-02,  6.9809e-03,\n",
      "         6.1352e-03, -2.6294e-03, -3.1017e-02,  2.6243e-02,  2.7201e-02,\n",
      "        -4.2901e-03,  1.9301e-02, -2.1207e-02, -3.3671e-02, -3.1217e-02,\n",
      "         6.5066e-03,  2.7173e-02,  3.1513e-02,  8.3830e-05, -1.5641e-02,\n",
      "        -3.0109e-02,  1.6290e-02, -4.8084e-03,  2.8899e-02, -4.4025e-03,\n",
      "        -1.3338e-02, -2.2227e-02,  1.6400e-03, -9.9538e-03, -2.7384e-02,\n",
      "         8.8400e-04, -1.5965e-02,  1.8518e-02,  2.1814e-02,  2.7947e-02,\n",
      "         2.9207e-02,  1.7507e-02,  1.1051e-02,  1.6562e-02, -3.3521e-02,\n",
      "         1.2367e-02,  6.3117e-03, -3.0777e-02, -1.0119e-02, -3.2875e-02,\n",
      "         1.9876e-02,  2.5285e-02, -1.7967e-03, -8.1559e-03,  2.7394e-02,\n",
      "        -2.3252e-02, -6.5550e-03, -2.6216e-02, -2.0705e-02,  2.8556e-02,\n",
      "         1.6800e-02,  1.5743e-03,  2.8316e-02,  1.5006e-02,  1.1886e-03,\n",
      "        -1.5562e-02, -3.0674e-02, -5.8166e-03,  1.3629e-03,  2.5214e-03,\n",
      "         1.5544e-02,  3.4694e-03,  2.1140e-02,  2.7473e-03, -3.0004e-02,\n",
      "         1.1869e-02, -1.1763e-02,  7.3276e-03, -2.8593e-02,  3.3902e-02,\n",
      "        -6.4871e-03, -2.1743e-02,  2.2879e-02, -1.1630e-02, -2.2267e-02,\n",
      "        -3.2318e-03,  3.3676e-03, -1.2853e-02,  1.8242e-02,  3.0522e-02,\n",
      "        -1.0736e-03,  3.3132e-02, -2.7127e-02,  3.1748e-02,  2.3755e-02,\n",
      "         1.6898e-02,  2.5242e-02,  6.4221e-03, -6.0177e-03, -1.1989e-02,\n",
      "        -3.1861e-02, -3.1566e-02, -3.5193e-02, -2.1316e-02, -1.5913e-02,\n",
      "         2.2527e-02, -3.5243e-02,  2.7659e-03,  3.5319e-02, -2.1937e-02,\n",
      "        -6.7410e-03, -2.8867e-02, -6.6908e-03,  1.6601e-02, -2.8745e-02,\n",
      "        -1.1122e-02, -1.9665e-02, -8.5236e-03,  3.1531e-02, -1.8995e-02,\n",
      "         2.4836e-02, -1.0712e-02,  1.5861e-02, -2.7326e-02,  6.4606e-03,\n",
      "         2.4985e-02, -3.6411e-03, -3.5472e-02, -3.4772e-02,  1.0534e-02,\n",
      "         1.9675e-02,  1.4745e-02, -7.7223e-03, -2.0280e-02, -1.5342e-02,\n",
      "        -2.9629e-02, -2.9189e-02,  5.0050e-03,  2.2354e-02,  3.3478e-02,\n",
      "        -9.7301e-03,  2.3630e-02,  1.5672e-03,  1.4516e-02,  1.6460e-02,\n",
      "         8.1221e-03, -1.5814e-03, -1.7094e-02, -8.9703e-03,  3.3870e-02,\n",
      "         3.0677e-02,  1.2907e-02, -1.1274e-02, -1.4837e-03,  1.6462e-02,\n",
      "         3.5444e-02, -3.0789e-02, -3.8700e-03,  2.4096e-02, -9.6586e-03,\n",
      "        -9.2596e-03, -1.3157e-02, -3.0595e-02,  3.1801e-02,  2.1921e-02,\n",
      "         1.7284e-02,  1.3197e-02, -2.4958e-02, -6.6629e-04, -1.1050e-03,\n",
      "        -1.6129e-02, -7.9483e-04,  1.0822e-02, -1.4541e-02,  5.4773e-03,\n",
      "        -1.8167e-02,  2.0274e-02, -3.0704e-02,  3.4098e-02,  3.4127e-02,\n",
      "         1.3918e-02,  2.1365e-02, -1.6390e-02, -3.1461e-02,  1.6880e-02,\n",
      "        -2.5817e-02], device='cuda:0'), 'fc2.weight': tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000, -0.0610],\n",
      "        [ 0.0000, -0.0451, -0.0497,  ...,  0.0612,  0.0000, -0.0475],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000, -0.0459],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0561,  0.0471,  0.0000],\n",
      "        [ 0.0000, -0.0477,  0.0000,  ...,  0.0547,  0.0000,  0.0588],\n",
      "        [ 0.0000,  0.0000,  0.0481,  ...,  0.0000,  0.0476,  0.0000]],\n",
      "       device='cuda:0'), 'fc2.bias': tensor([ 0.0377, -0.0600, -0.0549, -0.0076,  0.0439, -0.0386,  0.0246, -0.0511,\n",
      "        -0.0316,  0.0454, -0.0252,  0.0231,  0.0026,  0.0129, -0.0621, -0.0044,\n",
      "        -0.0324,  0.0036,  0.0502,  0.0513, -0.0481, -0.0118,  0.0233, -0.0561,\n",
      "        -0.0295,  0.0215,  0.0150, -0.0039, -0.0086, -0.0283,  0.0503, -0.0219,\n",
      "        -0.0110,  0.0011,  0.0468,  0.0343, -0.0310,  0.0098, -0.0293,  0.0178,\n",
      "         0.0592, -0.0253,  0.0372, -0.0323, -0.0176, -0.0210,  0.0173, -0.0494,\n",
      "        -0.0393,  0.0171, -0.0020, -0.0312,  0.0233,  0.0345,  0.0056,  0.0083,\n",
      "        -0.0521,  0.0446,  0.0414,  0.0108,  0.0326, -0.0088,  0.0514,  0.0603,\n",
      "         0.0238,  0.0614,  0.0622,  0.0398, -0.0165,  0.0178,  0.0152, -0.0082,\n",
      "        -0.0239,  0.0121, -0.0181, -0.0115,  0.0018, -0.0059, -0.0413, -0.0466,\n",
      "         0.0445,  0.0031,  0.0471,  0.0540, -0.0260,  0.0171, -0.0506, -0.0432,\n",
      "         0.0137,  0.0046, -0.0224,  0.0416,  0.0561,  0.0144,  0.0080, -0.0450,\n",
      "        -0.0012,  0.0494,  0.0020,  0.0378,  0.0587,  0.0066,  0.0130, -0.0356,\n",
      "        -0.0397,  0.0186,  0.0407, -0.0278, -0.0148, -0.0551,  0.0547,  0.0386,\n",
      "        -0.0143,  0.0579,  0.0188,  0.0433,  0.0296,  0.0219,  0.0417, -0.0053,\n",
      "         0.0365,  0.0129,  0.0558, -0.0451, -0.0152,  0.0232, -0.0341,  0.0469],\n",
      "       device='cuda:0'), 'fc3.weight': tensor([[ 0.0000,  0.0000, -0.0818,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0705,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000, -0.0852,  0.0000],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0670,  0.0000,  ..., -0.0716,  0.0797,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0695,  0.0000,  0.0765],\n",
      "        [-0.0633,  0.0000, -0.0678,  ...,  0.0000,  0.0000,  0.0849]],\n",
      "       device='cuda:0'), 'fc3.bias': tensor([ 0.0312,  0.0081,  0.0121, -0.0028, -0.0332, -0.0566, -0.0438,  0.0196,\n",
      "        -0.0658,  0.0469], device='cuda:0')})\n",
      "OrderedDict({'fc1.weight': tensor([[-0.0392, -0.0046,  0.0240,  ...,  0.0241, -0.0046, -0.0046],\n",
      "        [ 0.0219, -0.0046, -0.0046,  ..., -0.0046, -0.0046, -0.0046],\n",
      "        [-0.0046, -0.0046, -0.0391,  ..., -0.0046,  0.0287, -0.0046],\n",
      "        ...,\n",
      "        [-0.0347, -0.0046, -0.0046,  ..., -0.0046, -0.0046, -0.0345],\n",
      "        [-0.0367, -0.0046, -0.0046,  ..., -0.0046,  0.0251, -0.0046],\n",
      "        [-0.0046, -0.0046, -0.0046,  ..., -0.0046, -0.0046, -0.0046]],\n",
      "       device='cuda:0'), 'fc1.bias': tensor([-0.0261, -0.0212, -0.0405, -0.0222, -0.0411, -0.0111, -0.0002, -0.0237,\n",
      "        -0.0259,  0.0184,  0.0022,  0.0065, -0.0033, -0.0294, -0.0181,  0.0069,\n",
      "         0.0007, -0.0076, -0.0152, -0.0360, -0.0182, -0.0465, -0.0168, -0.0031,\n",
      "         0.0125, -0.0290, -0.0497,  0.0054, -0.0468,  0.0060, -0.0046, -0.0030,\n",
      "         0.0091, -0.0452, -0.0502, -0.0455, -0.0005,  0.0026, -0.0016, -0.0476,\n",
      "         0.0070, -0.0044, -0.0423,  0.0014,  0.0063,  0.0117, -0.0490,  0.0158,\n",
      "        -0.0309, -0.0336,  0.0123, -0.0407, -0.0430,  0.0165, -0.0279,  0.0086,\n",
      "         0.0092,  0.0015,  0.0030,  0.0163,  0.0041, -0.0466, -0.0028, -0.0012,\n",
      "        -0.0499, -0.0426,  0.0120,  0.0049, -0.0427, -0.0198, -0.0360,  0.0032,\n",
      "         0.0016, -0.0309, -0.0150, -0.0012, -0.0278, -0.0053, -0.0506, -0.0082,\n",
      "        -0.0091, -0.0178, -0.0462,  0.0110,  0.0120, -0.0195,  0.0041, -0.0364,\n",
      "        -0.0489, -0.0464, -0.0087,  0.0120,  0.0163, -0.0151, -0.0309, -0.0453,\n",
      "         0.0011, -0.0200,  0.0137, -0.0196, -0.0285, -0.0374, -0.0136, -0.0252,\n",
      "        -0.0426, -0.0143, -0.0312,  0.0033,  0.0066,  0.0127,  0.0140,  0.0023,\n",
      "        -0.0042,  0.0014, -0.0487, -0.0028, -0.0089, -0.0460, -0.0253, -0.0481,\n",
      "         0.0047,  0.0101, -0.0170, -0.0234,  0.0122, -0.0385, -0.0218, -0.0414,\n",
      "        -0.0359,  0.0133,  0.0016, -0.0136,  0.0131, -0.0002, -0.0140, -0.0308,\n",
      "        -0.0459, -0.0210, -0.0138, -0.0127,  0.0003, -0.0117,  0.0059, -0.0125,\n",
      "        -0.0452, -0.0033, -0.0270, -0.0079, -0.0438,  0.0187, -0.0217, -0.0370,\n",
      "         0.0077, -0.0268, -0.0375, -0.0184, -0.0118, -0.0281,  0.0030,  0.0153,\n",
      "        -0.0163,  0.0179, -0.0423,  0.0165,  0.0085,  0.0017,  0.0100, -0.0088,\n",
      "        -0.0212, -0.0272, -0.0471, -0.0468, -0.0504, -0.0365, -0.0311,  0.0073,\n",
      "        -0.0505, -0.0124,  0.0201, -0.0371, -0.0220, -0.0441, -0.0219,  0.0014,\n",
      "        -0.0440, -0.0263, -0.0349, -0.0237,  0.0163, -0.0342,  0.0096, -0.0259,\n",
      "         0.0006, -0.0425, -0.0088,  0.0098, -0.0189, -0.0507, -0.0500, -0.0047,\n",
      "         0.0045, -0.0005, -0.0229, -0.0355, -0.0306, -0.0448, -0.0444, -0.0102,\n",
      "         0.0071,  0.0183, -0.0249,  0.0084, -0.0136, -0.0007,  0.0012, -0.0071,\n",
      "        -0.0168, -0.0323, -0.0242,  0.0187,  0.0155, -0.0023, -0.0265, -0.0167,\n",
      "         0.0013,  0.0202, -0.0460, -0.0191,  0.0089, -0.0249, -0.0245, -0.0284,\n",
      "        -0.0458,  0.0166,  0.0067,  0.0021, -0.0020, -0.0402, -0.0159, -0.0163,\n",
      "        -0.0313, -0.0160, -0.0044, -0.0298, -0.0097, -0.0334,  0.0051, -0.0459,\n",
      "         0.0189,  0.0189, -0.0013,  0.0062, -0.0316, -0.0467,  0.0017, -0.0410],\n",
      "       device='cuda:0'), 'fc2.weight': tensor([[-0.0115, -0.0115, -0.0115,  ..., -0.0115, -0.0115, -0.0724],\n",
      "        [-0.0115, -0.0566, -0.0612,  ...,  0.0497, -0.0115, -0.0589],\n",
      "        [-0.0115, -0.0115, -0.0115,  ..., -0.0115, -0.0115, -0.0574],\n",
      "        ...,\n",
      "        [-0.0115, -0.0115, -0.0115,  ...,  0.0447,  0.0356, -0.0115],\n",
      "        [-0.0115, -0.0591, -0.0115,  ...,  0.0433, -0.0115,  0.0473],\n",
      "        [-0.0115, -0.0115,  0.0366,  ..., -0.0115,  0.0362, -0.0115]],\n",
      "       device='cuda:0'), 'fc2.bias': tensor([ 0.0338, -0.0639, -0.0588, -0.0116,  0.0400, -0.0426,  0.0207, -0.0551,\n",
      "        -0.0355,  0.0414, -0.0292,  0.0192, -0.0013,  0.0090, -0.0660, -0.0083,\n",
      "        -0.0364, -0.0004,  0.0462,  0.0473, -0.0521, -0.0157,  0.0193, -0.0601,\n",
      "        -0.0335,  0.0176,  0.0110, -0.0079, -0.0125, -0.0322,  0.0464, -0.0259,\n",
      "        -0.0149, -0.0029,  0.0429,  0.0304, -0.0349,  0.0059, -0.0333,  0.0138,\n",
      "         0.0552, -0.0293,  0.0332, -0.0363, -0.0215, -0.0249,  0.0134, -0.0534,\n",
      "        -0.0432,  0.0131, -0.0060, -0.0352,  0.0194,  0.0305,  0.0016,  0.0044,\n",
      "        -0.0561,  0.0406,  0.0374,  0.0069,  0.0286, -0.0127,  0.0475,  0.0563,\n",
      "         0.0198,  0.0574,  0.0583,  0.0359, -0.0204,  0.0138,  0.0112, -0.0121,\n",
      "        -0.0278,  0.0082, -0.0221, -0.0154, -0.0021, -0.0098, -0.0453, -0.0506,\n",
      "         0.0406, -0.0008,  0.0431,  0.0500, -0.0300,  0.0131, -0.0545, -0.0472,\n",
      "         0.0097,  0.0007, -0.0264,  0.0376,  0.0522,  0.0104,  0.0040, -0.0489,\n",
      "        -0.0051,  0.0454, -0.0020,  0.0339,  0.0547,  0.0026,  0.0091, -0.0395,\n",
      "        -0.0437,  0.0147,  0.0368, -0.0318, -0.0187, -0.0590,  0.0507,  0.0347,\n",
      "        -0.0182,  0.0539,  0.0149,  0.0394,  0.0256,  0.0179,  0.0377, -0.0093,\n",
      "         0.0326,  0.0090,  0.0519, -0.0491, -0.0191,  0.0192, -0.0380,  0.0429],\n",
      "       device='cuda:0'), 'fc3.weight': tensor([[ 0.0184,  0.0184, -0.0634,  ...,  0.0184,  0.0184,  0.0184],\n",
      "        [ 0.0184,  0.0184,  0.0889,  ...,  0.0184,  0.0184,  0.0184],\n",
      "        [ 0.0184,  0.0184,  0.0184,  ...,  0.0184, -0.0668,  0.0184],\n",
      "        ...,\n",
      "        [ 0.0184,  0.0854,  0.0184,  ..., -0.0531,  0.0981,  0.0184],\n",
      "        [ 0.0184,  0.0184,  0.0184,  ...,  0.0879,  0.0184,  0.0949],\n",
      "        [-0.0449,  0.0184, -0.0494,  ...,  0.0184,  0.0184,  0.1033]],\n",
      "       device='cuda:0'), 'fc3.bias': tensor([ 0.0324,  0.0092,  0.0133, -0.0016, -0.0321, -0.0554, -0.0426,  0.0208,\n",
      "        -0.0647,  0.0481], device='cuda:0')})\n",
      "Train loss: 2.3042548396694125\n",
      "Test accuracy: 0.0585\n",
      "Epoch 4\n",
      "OrderedDict({'fc1.weight': tensor([[-0.0346,  0.0000,  0.0287,  ...,  0.0287,  0.0000,  0.0000],\n",
      "        [ 0.0265,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000, -0.0345,  ...,  0.0000,  0.0333,  0.0000],\n",
      "        ...,\n",
      "        [-0.0301,  0.0000,  0.0000,  ...,  0.0000,  0.0000, -0.0299],\n",
      "        [-0.0321,  0.0000,  0.0000,  ...,  0.0000,  0.0297,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0'), 'fc1.bias': tensor([-1.0868e-02, -5.9395e-03, -2.5255e-02, -6.9755e-03, -2.5891e-02,\n",
      "         4.1298e-03,  1.4969e-02, -8.4799e-03, -1.0652e-02,  3.3648e-02,\n",
      "         1.7382e-02,  2.1708e-02,  1.1924e-02, -1.4142e-02, -2.9194e-03,\n",
      "         2.2122e-02,  1.5926e-02,  7.5681e-03,  2.5220e-05, -2.0818e-02,\n",
      "        -3.0350e-03, -3.1327e-02, -1.5511e-03,  1.2087e-02,  2.7704e-02,\n",
      "        -1.3782e-02, -3.4459e-02,  2.0656e-02, -3.1582e-02,  2.1182e-02,\n",
      "         1.0652e-02,  1.2198e-02,  2.4334e-02, -2.9982e-02, -3.5023e-02,\n",
      "        -3.0259e-02,  1.4693e-02,  1.7856e-02,  1.3606e-02, -3.2377e-02,\n",
      "         2.2182e-02,  1.0795e-02, -2.7106e-02,  1.6569e-02,  2.1490e-02,\n",
      "         2.6935e-02, -3.3763e-02,  3.1031e-02, -1.5672e-02, -1.8419e-02,\n",
      "         2.7500e-02, -2.5501e-02, -2.7811e-02,  3.1733e-02, -1.2646e-02,\n",
      "         2.3861e-02,  2.4408e-02,  1.6704e-02,  1.8171e-02,  3.1489e-02,\n",
      "         1.9330e-02, -3.1405e-02,  1.2452e-02,  1.4022e-02, -3.4676e-02,\n",
      "        -2.7369e-02,  2.7255e-02,  2.0146e-02, -2.7486e-02, -4.5679e-03,\n",
      "        -2.0807e-02,  1.8368e-02,  1.6832e-02, -1.5661e-02,  1.8277e-04,\n",
      "         1.4005e-02, -1.2626e-02,  9.8972e-03, -3.5431e-02,  6.9809e-03,\n",
      "         6.1352e-03, -2.6294e-03, -3.1017e-02,  2.6243e-02,  2.7201e-02,\n",
      "        -4.2901e-03,  1.9301e-02, -2.1207e-02, -3.3671e-02, -3.1217e-02,\n",
      "         6.5066e-03,  2.7173e-02,  3.1513e-02,  8.3830e-05, -1.5641e-02,\n",
      "        -3.0109e-02,  1.6290e-02, -4.8084e-03,  2.8899e-02, -4.4025e-03,\n",
      "        -1.3338e-02, -2.2227e-02,  1.6400e-03, -9.9538e-03, -2.7384e-02,\n",
      "         8.8400e-04, -1.5965e-02,  1.8518e-02,  2.1814e-02,  2.7947e-02,\n",
      "         2.9207e-02,  1.7507e-02,  1.1051e-02,  1.6562e-02, -3.3521e-02,\n",
      "         1.2367e-02,  6.3117e-03, -3.0777e-02, -1.0119e-02, -3.2875e-02,\n",
      "         1.9876e-02,  2.5285e-02, -1.7967e-03, -8.1559e-03,  2.7394e-02,\n",
      "        -2.3252e-02, -6.5550e-03, -2.6216e-02, -2.0705e-02,  2.8556e-02,\n",
      "         1.6800e-02,  1.5743e-03,  2.8316e-02,  1.5006e-02,  1.1886e-03,\n",
      "        -1.5562e-02, -3.0674e-02, -5.8166e-03,  1.3629e-03,  2.5214e-03,\n",
      "         1.5544e-02,  3.4694e-03,  2.1140e-02,  2.7473e-03, -3.0004e-02,\n",
      "         1.1869e-02, -1.1763e-02,  7.3276e-03, -2.8593e-02,  3.3902e-02,\n",
      "        -6.4871e-03, -2.1743e-02,  2.2879e-02, -1.1630e-02, -2.2267e-02,\n",
      "        -3.2318e-03,  3.3676e-03, -1.2853e-02,  1.8242e-02,  3.0522e-02,\n",
      "        -1.0736e-03,  3.3132e-02, -2.7127e-02,  3.1748e-02,  2.3755e-02,\n",
      "         1.6898e-02,  2.5242e-02,  6.4221e-03, -6.0177e-03, -1.1989e-02,\n",
      "        -3.1861e-02, -3.1566e-02, -3.5193e-02, -2.1316e-02, -1.5913e-02,\n",
      "         2.2527e-02, -3.5243e-02,  2.7659e-03,  3.5319e-02, -2.1937e-02,\n",
      "        -6.7410e-03, -2.8867e-02, -6.6908e-03,  1.6601e-02, -2.8745e-02,\n",
      "        -1.1122e-02, -1.9665e-02, -8.5236e-03,  3.1531e-02, -1.8995e-02,\n",
      "         2.4836e-02, -1.0712e-02,  1.5861e-02, -2.7326e-02,  6.4606e-03,\n",
      "         2.4985e-02, -3.6411e-03, -3.5472e-02, -3.4772e-02,  1.0534e-02,\n",
      "         1.9675e-02,  1.4745e-02, -7.7223e-03, -2.0280e-02, -1.5342e-02,\n",
      "        -2.9629e-02, -2.9189e-02,  5.0050e-03,  2.2354e-02,  3.3478e-02,\n",
      "        -9.7301e-03,  2.3630e-02,  1.5672e-03,  1.4516e-02,  1.6460e-02,\n",
      "         8.1221e-03, -1.5814e-03, -1.7094e-02, -8.9703e-03,  3.3870e-02,\n",
      "         3.0677e-02,  1.2907e-02, -1.1274e-02, -1.4837e-03,  1.6462e-02,\n",
      "         3.5444e-02, -3.0789e-02, -3.8700e-03,  2.4096e-02, -9.6586e-03,\n",
      "        -9.2596e-03, -1.3157e-02, -3.0595e-02,  3.1801e-02,  2.1921e-02,\n",
      "         1.7284e-02,  1.3197e-02, -2.4958e-02, -6.6629e-04, -1.1050e-03,\n",
      "        -1.6129e-02, -7.9483e-04,  1.0822e-02, -1.4541e-02,  5.4773e-03,\n",
      "        -1.8167e-02,  2.0274e-02, -3.0704e-02,  3.4098e-02,  3.4127e-02,\n",
      "         1.3918e-02,  2.1365e-02, -1.6390e-02, -3.1461e-02,  1.6880e-02,\n",
      "        -2.5817e-02], device='cuda:0'), 'fc2.weight': tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000, -0.0610],\n",
      "        [ 0.0000, -0.0451, -0.0497,  ...,  0.0612,  0.0000, -0.0475],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000, -0.0459],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0561,  0.0471,  0.0000],\n",
      "        [ 0.0000, -0.0477,  0.0000,  ...,  0.0547,  0.0000,  0.0588],\n",
      "        [ 0.0000,  0.0000,  0.0481,  ...,  0.0000,  0.0476,  0.0000]],\n",
      "       device='cuda:0'), 'fc2.bias': tensor([ 0.0377, -0.0600, -0.0549, -0.0076,  0.0439, -0.0386,  0.0246, -0.0511,\n",
      "        -0.0316,  0.0454, -0.0252,  0.0231,  0.0026,  0.0129, -0.0621, -0.0044,\n",
      "        -0.0324,  0.0036,  0.0502,  0.0513, -0.0481, -0.0118,  0.0233, -0.0561,\n",
      "        -0.0295,  0.0215,  0.0150, -0.0039, -0.0086, -0.0283,  0.0503, -0.0219,\n",
      "        -0.0110,  0.0011,  0.0468,  0.0343, -0.0310,  0.0098, -0.0293,  0.0178,\n",
      "         0.0592, -0.0253,  0.0372, -0.0323, -0.0176, -0.0210,  0.0173, -0.0494,\n",
      "        -0.0393,  0.0171, -0.0020, -0.0312,  0.0233,  0.0345,  0.0056,  0.0083,\n",
      "        -0.0521,  0.0446,  0.0414,  0.0108,  0.0326, -0.0088,  0.0514,  0.0603,\n",
      "         0.0238,  0.0614,  0.0622,  0.0398, -0.0165,  0.0178,  0.0152, -0.0082,\n",
      "        -0.0239,  0.0121, -0.0181, -0.0115,  0.0018, -0.0059, -0.0413, -0.0466,\n",
      "         0.0445,  0.0031,  0.0471,  0.0540, -0.0260,  0.0171, -0.0506, -0.0432,\n",
      "         0.0137,  0.0046, -0.0224,  0.0416,  0.0561,  0.0144,  0.0080, -0.0450,\n",
      "        -0.0012,  0.0494,  0.0020,  0.0378,  0.0587,  0.0066,  0.0130, -0.0356,\n",
      "        -0.0397,  0.0186,  0.0407, -0.0278, -0.0148, -0.0551,  0.0547,  0.0386,\n",
      "        -0.0143,  0.0579,  0.0188,  0.0433,  0.0296,  0.0219,  0.0417, -0.0053,\n",
      "         0.0365,  0.0129,  0.0558, -0.0451, -0.0152,  0.0232, -0.0341,  0.0469],\n",
      "       device='cuda:0'), 'fc3.weight': tensor([[ 0.0000,  0.0000, -0.0818,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0705,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000, -0.0852,  0.0000],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0670,  0.0000,  ..., -0.0716,  0.0797,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0695,  0.0000,  0.0765],\n",
      "        [-0.0633,  0.0000, -0.0678,  ...,  0.0000,  0.0000,  0.0849]],\n",
      "       device='cuda:0'), 'fc3.bias': tensor([ 0.0312,  0.0081,  0.0121, -0.0028, -0.0332, -0.0566, -0.0438,  0.0196,\n",
      "        -0.0658,  0.0469], device='cuda:0')})\n",
      "OrderedDict({'fc1.weight': tensor([[-0.0402, -0.0056,  0.0230,  ...,  0.0231, -0.0056, -0.0056],\n",
      "        [ 0.0209, -0.0056, -0.0056,  ..., -0.0056, -0.0056, -0.0056],\n",
      "        [-0.0056, -0.0056, -0.0401,  ..., -0.0056,  0.0277, -0.0056],\n",
      "        ...,\n",
      "        [-0.0357, -0.0056, -0.0056,  ..., -0.0056, -0.0056, -0.0356],\n",
      "        [-0.0377, -0.0056, -0.0056,  ..., -0.0056,  0.0241, -0.0056],\n",
      "        [-0.0056, -0.0056, -0.0056,  ..., -0.0056, -0.0056, -0.0056]],\n",
      "       device='cuda:0'), 'fc1.bias': tensor([-2.9418e-02, -2.4490e-02, -4.3805e-02, -2.5526e-02, -4.4441e-02,\n",
      "        -1.4420e-02, -3.5808e-03, -2.7030e-02, -2.9202e-02,  1.5098e-02,\n",
      "        -1.1680e-03,  3.1582e-03, -6.6265e-03, -3.2692e-02, -2.1469e-02,\n",
      "         3.5718e-03, -2.6236e-03, -1.0982e-02, -1.8525e-02, -3.9368e-02,\n",
      "        -2.1585e-02, -4.9877e-02, -2.0101e-02, -6.4630e-03,  9.1540e-03,\n",
      "        -3.2332e-02, -5.3009e-02,  2.1060e-03, -5.0132e-02,  2.6317e-03,\n",
      "        -7.8985e-03, -6.3521e-03,  5.7840e-03, -4.8533e-02, -5.3573e-02,\n",
      "        -4.8809e-02, -3.8570e-03, -6.9405e-04, -4.9442e-03, -5.0927e-02,\n",
      "         3.6318e-03, -7.7546e-03, -4.5656e-02, -1.9813e-03,  2.9395e-03,\n",
      "         8.3847e-03, -5.2313e-02,  1.2481e-02, -3.4222e-02, -3.6970e-02,\n",
      "         8.9504e-03, -4.4051e-02, -4.6361e-02,  1.3183e-02, -3.1196e-02,\n",
      "         5.3108e-03,  5.8575e-03, -1.8461e-03, -3.7865e-04,  1.2939e-02,\n",
      "         7.7983e-04, -4.9955e-02, -6.0984e-03, -4.5285e-03, -5.3226e-02,\n",
      "        -4.5920e-02,  8.7047e-03,  1.5961e-03, -4.6036e-02, -2.3118e-02,\n",
      "        -3.9357e-02, -1.8244e-04, -1.7182e-03, -3.4211e-02, -1.8367e-02,\n",
      "        -4.5448e-03, -3.1176e-02, -8.6528e-03, -5.3981e-02, -1.1569e-02,\n",
      "        -1.2415e-02, -2.1179e-02, -4.9567e-02,  7.6932e-03,  8.6507e-03,\n",
      "        -2.2840e-02,  7.5076e-04, -3.9757e-02, -5.2221e-02, -4.9767e-02,\n",
      "        -1.2043e-02,  8.6233e-03,  1.2963e-02, -1.8466e-02, -3.4191e-02,\n",
      "        -4.8659e-02, -2.2604e-03, -2.3358e-02,  1.0348e-02, -2.2953e-02,\n",
      "        -3.1888e-02, -4.0777e-02, -1.6910e-02, -2.8504e-02, -4.5934e-02,\n",
      "        -1.7666e-02, -3.4515e-02, -3.1644e-05,  3.2638e-03,  9.3968e-03,\n",
      "         1.0657e-02, -1.0430e-03, -7.4990e-03, -1.9881e-03, -5.2071e-02,\n",
      "        -6.1829e-03, -1.2238e-02, -4.9327e-02, -2.8669e-02, -5.1425e-02,\n",
      "         1.3264e-03,  6.7348e-03, -2.0347e-02, -2.6706e-02,  8.8438e-03,\n",
      "        -4.1802e-02, -2.5105e-02, -4.4766e-02, -3.9255e-02,  1.0006e-02,\n",
      "        -1.7499e-03, -1.6976e-02,  9.7655e-03, -3.5444e-03, -1.7361e-02,\n",
      "        -3.4112e-02, -4.9224e-02, -2.4367e-02, -1.7187e-02, -1.6029e-02,\n",
      "        -3.0062e-03, -1.5081e-02,  2.5901e-03, -1.5803e-02, -4.8554e-02,\n",
      "        -6.6806e-03, -3.0313e-02, -1.1222e-02, -4.7143e-02,  1.5352e-02,\n",
      "        -2.5037e-02, -4.0293e-02,  4.3287e-03, -3.0180e-02, -4.0817e-02,\n",
      "        -2.1782e-02, -1.5182e-02, -3.1403e-02, -3.0822e-04,  1.1972e-02,\n",
      "        -1.9624e-02,  1.4582e-02, -4.5677e-02,  1.3198e-02,  5.2050e-03,\n",
      "        -1.6517e-03,  6.6919e-03, -1.2128e-02, -2.4568e-02, -3.0539e-02,\n",
      "        -5.0411e-02, -5.0116e-02, -5.3743e-02, -3.9866e-02, -3.4463e-02,\n",
      "         3.9773e-03, -5.3793e-02, -1.5784e-02,  1.6769e-02, -4.0487e-02,\n",
      "        -2.5291e-02, -4.7417e-02, -2.5241e-02, -1.9491e-03, -4.7295e-02,\n",
      "        -2.9672e-02, -3.8215e-02, -2.7074e-02,  1.2981e-02, -3.7545e-02,\n",
      "         6.2860e-03, -2.9262e-02, -2.6894e-03, -4.5876e-02, -1.2089e-02,\n",
      "         6.4345e-03, -2.2191e-02, -5.4022e-02, -5.3322e-02, -8.0161e-03,\n",
      "         1.1253e-03, -3.8050e-03, -2.6272e-02, -3.8830e-02, -3.3892e-02,\n",
      "        -4.8179e-02, -4.7739e-02, -1.3545e-02,  3.8037e-03,  1.4928e-02,\n",
      "        -2.8280e-02,  5.0798e-03, -1.6983e-02, -4.0339e-03, -2.0901e-03,\n",
      "        -1.0428e-02, -2.0131e-02, -3.5644e-02, -2.7520e-02,  1.5320e-02,\n",
      "         1.2127e-02, -5.6435e-03, -2.9825e-02, -2.0034e-02, -2.0876e-03,\n",
      "         1.6894e-02, -4.9340e-02, -2.2420e-02,  5.5459e-03, -2.8209e-02,\n",
      "        -2.7810e-02, -3.1707e-02, -4.9145e-02,  1.3251e-02,  3.3712e-03,\n",
      "        -1.2665e-03, -5.3532e-03, -4.3508e-02, -1.9216e-02, -1.9655e-02,\n",
      "        -3.4679e-02, -1.9345e-02, -7.7280e-03, -3.3091e-02, -1.3073e-02,\n",
      "        -3.6717e-02,  1.7239e-03, -4.9254e-02,  1.5548e-02,  1.5577e-02,\n",
      "        -4.6324e-03,  2.8147e-03, -3.4941e-02, -5.0011e-02, -1.6700e-03,\n",
      "        -4.4367e-02], device='cuda:0'), 'fc2.weight': tensor([[-0.0140, -0.0140, -0.0140,  ..., -0.0140, -0.0140, -0.0749],\n",
      "        [-0.0140, -0.0591, -0.0637,  ...,  0.0472, -0.0140, -0.0614],\n",
      "        [-0.0140, -0.0140, -0.0140,  ..., -0.0140, -0.0140, -0.0599],\n",
      "        ...,\n",
      "        [-0.0140, -0.0140, -0.0140,  ...,  0.0421,  0.0331, -0.0140],\n",
      "        [-0.0140, -0.0616, -0.0140,  ...,  0.0407, -0.0140,  0.0448],\n",
      "        [-0.0140, -0.0140,  0.0341,  ..., -0.0140,  0.0337, -0.0140]],\n",
      "       device='cuda:0'), 'fc2.bias': tensor([ 0.0329, -0.0648, -0.0597, -0.0125,  0.0391, -0.0434,  0.0198, -0.0559,\n",
      "        -0.0364,  0.0406, -0.0301,  0.0183, -0.0022,  0.0081, -0.0669, -0.0092,\n",
      "        -0.0373, -0.0013,  0.0453,  0.0464, -0.0529, -0.0166,  0.0185, -0.0610,\n",
      "        -0.0343,  0.0167,  0.0101, -0.0087, -0.0134, -0.0331,  0.0455, -0.0267,\n",
      "        -0.0158, -0.0038,  0.0420,  0.0295, -0.0358,  0.0050, -0.0341,  0.0130,\n",
      "         0.0544, -0.0302,  0.0323, -0.0371, -0.0224, -0.0258,  0.0125, -0.0543,\n",
      "        -0.0441,  0.0123, -0.0068, -0.0361,  0.0185,  0.0297,  0.0008,  0.0035,\n",
      "        -0.0570,  0.0398,  0.0365,  0.0060,  0.0277, -0.0136,  0.0466,  0.0554,\n",
      "         0.0189,  0.0566,  0.0574,  0.0350, -0.0213,  0.0129,  0.0104, -0.0130,\n",
      "        -0.0287,  0.0073, -0.0229, -0.0163, -0.0030, -0.0107, -0.0462, -0.0514,\n",
      "         0.0397, -0.0017,  0.0423,  0.0491, -0.0309,  0.0123, -0.0554, -0.0480,\n",
      "         0.0088, -0.0002, -0.0272,  0.0368,  0.0513,  0.0095,  0.0031, -0.0498,\n",
      "        -0.0060,  0.0446, -0.0028,  0.0330,  0.0539,  0.0018,  0.0082, -0.0404,\n",
      "        -0.0445,  0.0138,  0.0359, -0.0326, -0.0196, -0.0599,  0.0499,  0.0338,\n",
      "        -0.0191,  0.0530,  0.0140,  0.0385,  0.0248,  0.0170,  0.0368, -0.0101,\n",
      "         0.0317,  0.0081,  0.0510, -0.0499, -0.0200,  0.0184, -0.0389,  0.0421],\n",
      "       device='cuda:0'), 'fc3.weight': tensor([[ 0.0225,  0.0225, -0.0594,  ...,  0.0225,  0.0225,  0.0225],\n",
      "        [ 0.0225,  0.0225,  0.0930,  ...,  0.0225,  0.0225,  0.0225],\n",
      "        [ 0.0225,  0.0225,  0.0225,  ...,  0.0225, -0.0628,  0.0225],\n",
      "        ...,\n",
      "        [ 0.0225,  0.0895,  0.0225,  ..., -0.0491,  0.1021,  0.0225],\n",
      "        [ 0.0225,  0.0225,  0.0225,  ...,  0.0919,  0.0225,  0.0990],\n",
      "        [-0.0409,  0.0225, -0.0453,  ...,  0.0225,  0.0225,  0.1074]],\n",
      "       device='cuda:0'), 'fc3.bias': tensor([ 0.0326,  0.0095,  0.0135, -0.0014, -0.0318, -0.0552, -0.0424,  0.0210,\n",
      "        -0.0644,  0.0483], device='cuda:0')})\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 59\u001b[0m\n\u001b[0;32m     57\u001b[0m running_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;66;03m# Pasamos todas las imagenes de train por la red net\u001b[39;00m\n\u001b[1;32m---> 59\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m images, labels \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[0;32m     60\u001b[0m     images, labels \u001b[38;5;241m=\u001b[39m images\u001b[38;5;241m.\u001b[39mto(device), labels\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     62\u001b[0m     outputs_net \u001b[38;5;241m=\u001b[39m pruned_net(images)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\utils\\data\\dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\utils\\data\\dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    674\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 675\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    677\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torchvision\\datasets\\mnist.py:145\u001b[0m, in \u001b[0;36mMNIST.__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m    142\u001b[0m img \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mfromarray(img\u001b[38;5;241m.\u001b[39mnumpy(), mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mL\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    144\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 145\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_transform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    148\u001b[0m     target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_transform(target)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torchvision\\transforms\\transforms.py:95\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[1;34m(self, img)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, img):\n\u001b[0;32m     94\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms:\n\u001b[1;32m---> 95\u001b[0m         img \u001b[38;5;241m=\u001b[39m \u001b[43mt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torchvision\\transforms\\transforms.py:277\u001b[0m, in \u001b[0;36mNormalize.forward\u001b[1;34m(self, tensor)\u001b[0m\n\u001b[0;32m    269\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, tensor: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m    270\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    271\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m    272\u001b[0m \u001b[38;5;124;03m        tensor (Tensor): Tensor image to be normalized.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    275\u001b[0m \u001b[38;5;124;03m        Tensor: Normalized Tensor image.\u001b[39;00m\n\u001b[0;32m    276\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 277\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormalize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torchvision\\transforms\\functional.py:349\u001b[0m, in \u001b[0;36mnormalize\u001b[1;34m(tensor, mean, std, inplace)\u001b[0m\n\u001b[0;32m    346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tensor, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[0;32m    347\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimg should be Tensor Image. Got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(tensor)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 349\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF_t\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormalize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmean\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torchvision\\transforms\\_functional_tensor.py:915\u001b[0m, in \u001b[0;36mnormalize\u001b[1;34m(tensor, mean, std, inplace)\u001b[0m\n\u001b[0;32m    910\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    911\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected tensor to be a tensor image of size (..., C, H, W). Got tensor.size() = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtensor\u001b[38;5;241m.\u001b[39msize()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    912\u001b[0m     )\n\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m inplace:\n\u001b[1;32m--> 915\u001b[0m     tensor \u001b[38;5;241m=\u001b[39m \u001b[43mtensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    917\u001b[0m dtype \u001b[38;5;241m=\u001b[39m tensor\u001b[38;5;241m.\u001b[39mdtype\n\u001b[0;32m    918\u001b[0m mean \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mas_tensor(mean, dtype\u001b[38;5;241m=\u001b[39mdtype, device\u001b[38;5;241m=\u001b[39mtensor\u001b[38;5;241m.\u001b[39mdevice)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# train loop\n",
    "train_loss = []\n",
    "test_accuracies = []\n",
    "epochs = 10\n",
    "accuracy_threshold = 0.6\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f\"Epoch {epoch + 1}\")\n",
    "    if epoch + 1 == 1:\n",
    "        pruned_net = prune_weights(net)\n",
    "\n",
    "        running_loss = 0.0\n",
    "        # Pasamos todas las imagenes de train por la red net\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            outputs_net = pruned_net(images)\n",
    "            loss = criterion(outputs_net, labels)\n",
    "\n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        train_loss.append(running_loss / len(train_loader))\n",
    "        print(f\"Train loss: {running_loss / len(train_loader)}\")\n",
    "\n",
    "        # Evaluamos el modelo en el conjunto de test\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in test_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "                outputs_net = pruned_net(images)\n",
    "                _, predicted = torch.max(outputs_net.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "        test_accuracies.append(correct / total)\n",
    "        print(f\"Test accuracy: {correct / total}\")\n",
    "\n",
    "        if correct / total > accuracy_threshold:\n",
    "            break\n",
    "    \n",
    "    else:\n",
    "        # Crear una copia de la red neuronal original\n",
    "        varied_net = copy.deepcopy(net)\n",
    "        print(varied_net.state_dict())\n",
    "\n",
    "        # Actualizar los pesos de la red neuronal copiada\n",
    "        with torch.no_grad():  # Desactiva el c√°lculo del gradiente para evitar que se almacenen gradientes innecesarios\n",
    "            for param, varianza in zip(varied_net.parameters(), varianzas):\n",
    "                param += varianza  # Sumar varianza a cada peso\n",
    "\n",
    "        print(varied_net.state_dict())\n",
    "\n",
    "        pruned_net = prune_weights(varied_net)\n",
    "\n",
    "        running_loss = 0.0\n",
    "        # Pasamos todas las imagenes de train por la red net\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            outputs_net = pruned_net(images)\n",
    "            loss = criterion(outputs_net, labels)\n",
    "\n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        train_loss.append(running_loss / len(train_loader))\n",
    "        print(f\"Train loss: {running_loss / len(train_loader)}\")\n",
    "\n",
    "        # Evaluamos el modelo en el conjunto de test\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in test_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "                outputs_net = pruned_net(images)\n",
    "                _, predicted = torch.max(outputs_net.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "        test_accuracies.append(correct / total)\n",
    "        print(f\"Test accuracy: {correct / total}\")\n",
    "\n",
    "        if correct / total > accuracy_threshold:\n",
    "            break\n",
    "\n",
    "        # actualizmos el vector de varianzas\n",
    "        if improvements(train_loss) == 0:## +mejoras que peoras\n",
    "            varianzas = [varianza * (1/0.82) for varianza in varianzas]\n",
    "        \n",
    "        elif improvements(train_loss) == 1: ## -mejoras que peoras\n",
    "            varianzas = [varianza * 0.82 for varianza in varianzas]\n",
    "\n",
    "        \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
