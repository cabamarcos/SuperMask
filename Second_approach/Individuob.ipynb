{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.init as init\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "import random\n",
    "from ast import Param\n",
    "import json\n",
    "import math\n",
    "\n",
    "from utils.prune import apply_mask\n",
    "from utils.count_improvement import improvements\n",
    "from utils.normalize import normalize_weights\n",
    "from utils.binary_ind import make_to_binary, modify_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Verificar si la GPU está disponible y establecer el dispositivo\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(784, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 784)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net().to(device)\n",
    "individuo = Net().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos el transform para los datos de MNIST\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "# Cargamos el dataset de MNIST\n",
    "train_dataset = datasets.MNIST('./data', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.MNIST('./data', train=False, download=True, transform=transform)\n",
    "\n",
    "# Definimos los DataLoaders para los conjuntos de entrenamiento y prueba\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=4)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1000, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos la función de pérdida para calcular el error\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train loop\n",
    "train_loss = []\n",
    "train_loss_mean = []\n",
    "test_accuracies = []\n",
    "n_individuo = 1\n",
    "accuracy_threshold = 0.4\n",
    "\n",
    "#Guardo el mejor individuo y la red original que tendrá que ser reestablecida cad epoca\n",
    "individuo = make_to_binary(individuo)\n",
    "best_individo_state_dict = individuo.state_dict()\n",
    "net_state_dict = net.state_dict()\n",
    "\n",
    "#train loop\n",
    "while True:\n",
    "    net.load_state_dict(net_state_dict)\n",
    "    if n_individuo == 1:\n",
    "        print(f\" --------------------- Individuo {n_individuo} --------------------- \")\n",
    "\n",
    "        masked_net = apply_mask(net, individuo)\n",
    "    \n",
    "        running_loss = 0.0\n",
    "        # Train for 1 epoch\n",
    "        for i, data in enumerate(train_loader, 0):\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "            #optimizer.zero_grad()\n",
    "            outputs = masked_net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            #loss.backward()\n",
    "            #optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        train_loss.append(running_loss / len(train_loader))\n",
    "\n",
    "        masked_net.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for data in test_loader:\n",
    "                images, labels = data[0].to(device), data[1].to(device)\n",
    "                outputs = masked_net(images)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "        accuracy = correct / total\n",
    "        #train_loss_mean.append(np.mean(train_loss))\n",
    "        test_accuracies.append(accuracy)\n",
    "        #print(f\"Accuracy: {accuracy}, loss mean: {train_loss_mean[-1]}\")\n",
    "        print(f\"Accuracy: {accuracy}\", f\"Loss: {train_loss[-1]}\")\n",
    "        best_loss = train_loss[-1]\n",
    "        if accuracy > accuracy_threshold:\n",
    "            break\n",
    "        n_individuo += 1\n",
    "\n",
    "        #Variamos el individuo desde el anterior para obtener uno nuevo\n",
    "        nuevo_individuo = modify_weights(individuo)\n",
    "        \n",
    "    else:\n",
    "        print(f\" --------------------- Individuo {n_individuo} --------------------- \")\n",
    "\n",
    "        masked_net = apply_mask(net, nuevo_individuo)\n",
    "        \n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(train_loader, 0):\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "            outputs = masked_net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item()\n",
    "        train_loss.append(running_loss / len(train_loader))\n",
    "\n",
    "        masked_net.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for data in test_loader:\n",
    "                images, labels = data[0].to(device), data[1].to(device)\n",
    "                outputs = masked_net(images)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "        accuracy = correct / total\n",
    "        test_accuracies.append(accuracy)\n",
    "        print(f\"Accuracy: {accuracy}\", f\"Loss: {train_loss[-1]}\")\n",
    "        if accuracy > accuracy_threshold:\n",
    "            break\n",
    "\n",
    "        # Verificamos que individuo tiene mejor desempeño\n",
    "        if train_loss[-1] < best_loss:\n",
    "            print(\"Nuevo mejor individuo\")\n",
    "            best_loss = train_loss[-1]\n",
    "            best_individo_state_dict = nuevo_individuo.state_dict()\n",
    "        \n",
    "        # actualizamos el individuo\n",
    "        individuo.load_state_dict(best_individo_state_dict)\n",
    "\n",
    "        # Variamos el individuo desde el anterior para obtener uno nuevo\n",
    "        nuevo_individuo = modify_weights(individuo)\n",
    "\n",
    "        n_individuo += 1         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_loss)\n",
    "print(test_accuracies)\n",
    "print(max(test_accuracies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos la figura y definimos dos subgráficos (1 fila, 2 columnas)\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "# Primer gráfico en la posición 1 (izquierda)\n",
    "plt.subplot(1, 2, 1)  # 1 fila, 2 columnas, primer gráfico\n",
    "plt.plot(train_loss, color='blue', marker='o')\n",
    "plt.title(\"Gráfico de Pérdida\")\n",
    "plt.xlabel(\"Pérdida\")\n",
    "plt.ylabel(\"Valores\")\n",
    "\n",
    "# Calcular la regresión lineal para train_loss\n",
    "epochs = np.arange(len(train_loss))\n",
    "m, b = np.polyfit(epochs, train_loss, 1)\n",
    "plt.plot(epochs, m*epochs + b, color='red', linestyle='--', label='Tendencia')\n",
    "\n",
    "\n",
    "# Segundo gráfico en la posición 2 (derecha)\n",
    "plt.subplot(1, 2, 2)  # 1 fila, 2 columnas, segundo gráfico\n",
    "plt.plot(test_accuracies, color='green', marker='s')\n",
    "plt.title(\"Gráfico de aciertos\")\n",
    "plt.xlabel(\"% Aciertos\")\n",
    "plt.ylabel(\"Valores\")\n",
    "\n",
    "# Calcular la regresión lineal para test_accuracies\n",
    "epochs_test = np.arange(len(test_accuracies))\n",
    "m, b = np.polyfit(epochs_test, test_accuracies, 1)\n",
    "plt.plot(epochs_test, m*epochs_test + b, color='red', linestyle='--', label='Tendencia')\n",
    "\n",
    "# Mostramos los gráficos\n",
    "plt.tight_layout()  # Ajustamos para que no se solapen los gráficos\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
