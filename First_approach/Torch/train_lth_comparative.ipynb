{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "faba6084",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models, datasets, transforms\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "be6a7e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "sparsity = 0.9\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eae4d6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset Animals10\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "data_dir = \"./animals10\"\n",
    "\n",
    "train_dataset = datasets.ImageFolder(root=os.path.join(data_dir, \"train\"), transform=transform)\n",
    "test_dataset = datasets.ImageFolder(root=os.path.join(data_dir, \"test\"), transform=transform)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "840aa0c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Usuario\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Usuario\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n",
      "C:\\Users\\Usuario\\AppData\\Local\\Temp\\ipykernel_14068\\833630905.py:9: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net.load_state_dict(torch.load(\"net.pth\"))\n",
      "C:\\Users\\Usuario\\AppData\\Local\\Temp\\ipykernel_14068\\833630905.py:10: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  mask_model.load_state_dict(torch.load(\"mask.pth\"))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AlexNet(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU(inplace=True)\n",
       "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.5, inplace=False)\n",
       "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Dropout(p=0.5, inplace=False)\n",
       "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): Linear(in_features=4096, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = models.alexnet(pretrained=False)\n",
    "net.classifier[6] = nn.Linear(net.classifier[6].in_features, 10)\n",
    "mask_model = models.alexnet(pretrained=False)\n",
    "mask_model.classifier[6] = nn.Linear(mask_model.classifier[6].in_features, 10)\n",
    "\n",
    "net.load_state_dict(torch.load(\"net.pth\"))\n",
    "mask_model.load_state_dict(torch.load(\"mask.pth\"))\n",
    "net.to(device)\n",
    "mask_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1960446b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mask_from_mask_model(mask_model, keep_ratio=0.1):\n",
    "    all_scores = []\n",
    "\n",
    "    for name, param in mask_model.named_parameters():\n",
    "        if 'weight' in name:\n",
    "            all_scores.append(param.data.cpu().abs().flatten().numpy())\n",
    "\n",
    "    all_scores = np.concatenate(all_scores)\n",
    "    threshold = np.percentile(all_scores, 100 * (1 - keep_ratio))\n",
    "\n",
    "    mask = {}\n",
    "    for name, param in mask_model.named_parameters():\n",
    "        if 'weight' in name:\n",
    "            mask_tensor = (param.data.abs() > threshold).float().to(device)\n",
    "            mask[name] = mask_tensor\n",
    "\n",
    "    return mask\n",
    "\n",
    "mask = create_mask_from_mask_model(mask_model, keep_ratio=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b029375f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, param in net.named_parameters():\n",
    "    if name in mask:\n",
    "        param.data *= mask[name]  # pruning: poner a cero\n",
    "        param.register_hook(lambda grad, name=name: grad * mask[name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2478ebfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imprimir numero de parametros que están a cero\n",
    "def count_zero_params(model):\n",
    "    zero_count = 0\n",
    "    total_count = 0\n",
    "    for name, param in model.named_parameters():\n",
    "        if 'weight' in name:\n",
    "            zero_count += (param.data == 0).sum().item()\n",
    "            total_count += param.numel()\n",
    "    return zero_count, total_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a11737b",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_weights = {name: param.clone().detach() for name, param in net.named_parameters() if name in mask}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2495c534",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of zero parameters: 51331909 out of 57035456 (90.00%)\n",
      "\n",
      "📊 [Epoch 1]\n",
      "   🔧 Train Accuracy : 22.64% |  Train Loss: 2.3183\n",
      "   🧪 Test Accuracy  : 22.95% | Test Loss: 2.0887\n",
      "Number of zero parameters: 51331909 out of 57035456 (90.00%)\n",
      "\n",
      "📊 [Epoch 2]\n",
      "   🔧 Train Accuracy : 37.41% |  Train Loss: 1.9816\n",
      "   🧪 Test Accuracy  : 37.40% | Test Loss: 1.7850\n",
      "Number of zero parameters: 51331909 out of 57035456 (90.00%)\n",
      "\n",
      "📊 [Epoch 3]\n",
      "   🔧 Train Accuracy : 46.29% |  Train Loss: 1.7053\n",
      "   🧪 Test Accuracy  : 45.53% | Test Loss: 1.5377\n",
      "Number of zero parameters: 51331909 out of 57035456 (90.00%)\n",
      "\n",
      "📊 [Epoch 4]\n",
      "   🔧 Train Accuracy : 53.13% |  Train Loss: 1.5073\n",
      "   🧪 Test Accuracy  : 53.39% | Test Loss: 1.3644\n",
      "Number of zero parameters: 51331909 out of 57035456 (90.00%)\n",
      "\n",
      "📊 [Epoch 5]\n",
      "   🔧 Train Accuracy : 53.16% |  Train Loss: 1.3856\n",
      "   🧪 Test Accuracy  : 51.29% | Test Loss: 1.4021\n",
      "Number of zero parameters: 51331909 out of 57035456 (90.00%)\n",
      "\n",
      "📊 [Epoch 6]\n",
      "   🔧 Train Accuracy : 62.05% |  Train Loss: 1.2852\n",
      "   🧪 Test Accuracy  : 59.55% | Test Loss: 1.1832\n",
      "Number of zero parameters: 51331909 out of 57035456 (90.00%)\n",
      "\n",
      "📊 [Epoch 7]\n",
      "   🔧 Train Accuracy : 64.43% |  Train Loss: 1.1875\n",
      "   🧪 Test Accuracy  : 60.39% | Test Loss: 1.1602\n",
      "Number of zero parameters: 51331909 out of 57035456 (90.00%)\n",
      "\n",
      "📊 [Epoch 8]\n",
      "   🔧 Train Accuracy : 66.86% |  Train Loss: 1.1151\n",
      "   🧪 Test Accuracy  : 62.37% | Test Loss: 1.0953\n",
      "Number of zero parameters: 51331909 out of 57035456 (90.00%)\n",
      "\n",
      "📊 [Epoch 9]\n",
      "   🔧 Train Accuracy : 69.36% |  Train Loss: 1.0577\n",
      "   🧪 Test Accuracy  : 64.34% | Test Loss: 1.0445\n",
      "Number of zero parameters: 51331909 out of 57035456 (90.00%)\n",
      "\n",
      "📊 [Epoch 10]\n",
      "   🔧 Train Accuracy : 72.40% |  Train Loss: 1.0230\n",
      "   🧪 Test Accuracy  : 66.11% | Test Loss: 1.0142\n",
      "Number of zero parameters: 51331909 out of 57035456 (90.00%)\n",
      "\n",
      "📊 [Epoch 11]\n",
      "   🔧 Train Accuracy : 72.10% |  Train Loss: 0.9625\n",
      "   🧪 Test Accuracy  : 65.52% | Test Loss: 1.0114\n",
      "Number of zero parameters: 51331909 out of 57035456 (90.00%)\n",
      "\n",
      "📊 [Epoch 12]\n",
      "   🔧 Train Accuracy : 72.39% |  Train Loss: 0.9176\n",
      "   🧪 Test Accuracy  : 64.07% | Test Loss: 1.0380\n",
      "Number of zero parameters: 51331909 out of 57035456 (90.00%)\n",
      "\n",
      "📊 [Epoch 13]\n",
      "   🔧 Train Accuracy : 76.97% |  Train Loss: 0.8772\n",
      "   🧪 Test Accuracy  : 67.56% | Test Loss: 0.9460\n",
      "Number of zero parameters: 51331909 out of 57035456 (90.00%)\n",
      "\n",
      "📊 [Epoch 14]\n",
      "   🔧 Train Accuracy : 77.13% |  Train Loss: 0.8319\n",
      "   🧪 Test Accuracy  : 67.49% | Test Loss: 0.9562\n",
      "Number of zero parameters: 51331909 out of 57035456 (90.00%)\n",
      "\n",
      "📊 [Epoch 15]\n",
      "   🔧 Train Accuracy : 79.32% |  Train Loss: 0.8017\n",
      "   🧪 Test Accuracy  : 68.19% | Test Loss: 0.9334\n",
      "Number of zero parameters: 51331909 out of 57035456 (90.00%)\n",
      "\n",
      "📊 [Epoch 16]\n",
      "   🔧 Train Accuracy : 79.58% |  Train Loss: 0.7732\n",
      "   🧪 Test Accuracy  : 67.53% | Test Loss: 0.9495\n",
      "Number of zero parameters: 51331909 out of 57035456 (90.00%)\n",
      "\n",
      "📊 [Epoch 17]\n",
      "   🔧 Train Accuracy : 80.79% |  Train Loss: 0.7329\n",
      "   🧪 Test Accuracy  : 66.80% | Test Loss: 0.9717\n",
      "Number of zero parameters: 51331909 out of 57035456 (90.00%)\n",
      "\n",
      "📊 [Epoch 18]\n",
      "   🔧 Train Accuracy : 81.63% |  Train Loss: 0.7081\n",
      "   🧪 Test Accuracy  : 68.02% | Test Loss: 0.9546\n",
      "Number of zero parameters: 51331909 out of 57035456 (90.00%)\n",
      "\n",
      "📊 [Epoch 19]\n",
      "   🔧 Train Accuracy : 86.07% |  Train Loss: 0.6845\n",
      "   🧪 Test Accuracy  : 69.45% | Test Loss: 0.9029\n",
      "Number of zero parameters: 51331909 out of 57035456 (90.00%)\n",
      "\n",
      "📊 [Epoch 20]\n",
      "   🔧 Train Accuracy : 86.16% |  Train Loss: 0.6292\n",
      "   🧪 Test Accuracy  : 70.29% | Test Loss: 0.9278\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "def evaluate(model, dataloader):\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "    total_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for x, y in dataloader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            out = model(x)\n",
    "            loss = criterion(out, y)\n",
    "            total_loss += loss.item()\n",
    "            _, pred = out.max(1)\n",
    "            correct += (pred == y).sum().item()\n",
    "            total += y.size(0)\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    accuracy = correct / total\n",
    "    return accuracy, avg_loss\n",
    "\n",
    "for epoch in range(1, 21):\n",
    "    zero_count, total_count = count_zero_params(net)\n",
    "    print(f\"Number of zero parameters: {zero_count} out of {total_count} ({100 * zero_count / total_count:.2f}%)\")\n",
    "    net.train()\n",
    "    running_loss = 0.0\n",
    "    for inputs, targets in train_loader:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    train_loss = running_loss / len(train_loader)\n",
    "    train_acc, _ = evaluate(net, train_loader)\n",
    "    test_acc, test_loss = evaluate(net, test_loader)\n",
    "\n",
    "    print(f\"\\n📊 [Epoch {epoch}]\")\n",
    "    print(f\"   🔧 Train Accuracy : {train_acc*100:.2f}% |  Train Loss: {train_loss:.4f}\")\n",
    "    print(f\"   🧪 Test Accuracy  : {test_acc*100:.2f}% | Test Loss: {test_loss:.4f}\")\n",
    "\n",
    "    # Verificar que pesos en 0 no se modifican\n",
    "    for name, param in net.named_parameters():\n",
    "        if name in mask:\n",
    "            original = initial_weights[name]\n",
    "            current = param.detach()\n",
    "            changed = ((original == 0) & (current != 0)).sum().item()\n",
    "            if changed > 0:\n",
    "                print(f\"⚠️ Warning: {changed} pesos enmascarados en '{name}' han cambiado.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
