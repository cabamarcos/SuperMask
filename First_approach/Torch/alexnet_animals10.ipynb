{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0142d840",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from utils.apply_mask_alexnet import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1ea690",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuración\n",
    "batch_size = 64\n",
    "threshold_accuracy = 0.70\n",
    "sparsity_percentage = 0.3  # Porcentaje de pesos a conservar (más altos)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ca4f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset Animals10\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "data_dir = \"./animals10\"\n",
    "\n",
    "train_dataset = datasets.ImageFolder(root=os.path.join(data_dir, \"train\"), transform=transform)\n",
    "test_dataset = datasets.ImageFolder(root=os.path.join(data_dir, \"test\"), transform=transform)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75603446",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AlexNet(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU(inplace=True)\n",
       "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.5, inplace=False)\n",
       "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Dropout(p=0.5, inplace=False)\n",
       "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): Linear(in_features=4096, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = models.alexnet(pretrained=False)\n",
    "net.classifier[6] = nn.Linear(net.classifier[6].in_features, 10)\n",
    "\n",
    "mask = models.alexnet(pretrained=False)\n",
    "mask.classifier[6] = nn.Linear(mask.classifier[6].in_features, 10)\n",
    "\n",
    "net.to(device)\n",
    "mask.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1288db31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Congelar los parámetros de net (no se entrenarán)\n",
    "for param in net.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc636eb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Epoch 1 =====\n",
      "Epoch 1: Avg Loss = 2.2195, Test Accuracy = 18.41%\n",
      "\n",
      "===== Epoch 2 =====\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 35\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[38;5;66;03m# # Verificar gradientes\u001b[39;00m\n\u001b[0;32m     28\u001b[0m     \u001b[38;5;66;03m# for name, param in mask.named_parameters():\u001b[39;00m\n\u001b[0;32m     29\u001b[0m     \u001b[38;5;66;03m#     if param.grad is not None:\u001b[39;00m\n\u001b[0;32m     30\u001b[0m     \u001b[38;5;66;03m#         print(f\"[Grad] {name}: grad norm = {param.grad.norm().item():.6f}\")\u001b[39;00m\n\u001b[0;32m     31\u001b[0m     \u001b[38;5;66;03m#     else:\u001b[39;00m\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;66;03m#         print(f\"[Grad] {name}: NO grad\")\u001b[39;00m\n\u001b[0;32m     33\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m---> 35\u001b[0m     running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     36\u001b[0m     \u001b[38;5;66;03m# if batch_idx % 10 == 0:\u001b[39;00m\n\u001b[0;32m     37\u001b[0m     \u001b[38;5;66;03m#     print(f\"Batch {batch_idx}, Loss: {loss.item():.4f}\")\u001b[39;00m\n\u001b[0;32m     39\u001b[0m avg_loss \u001b[38;5;241m=\u001b[39m running_loss \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(train_loader)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(mask.parameters(), lr=0.001)\n",
    "epoch = 0\n",
    "losses = []\n",
    "accuracies = []\n",
    "\n",
    "while True:\n",
    "    masked_model = MaskedForward(net, mask, sparsity_percentage).to(device)\n",
    "    # Guardar copia de los pesos de net para verificar que no cambian\n",
    "    # net_before = [p.clone().detach() for p in net.parameters()]\n",
    "    masked_model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    epoch += 1\n",
    "\n",
    "    print(f\"\\n===== Epoch {epoch} =====\")\n",
    "\n",
    "        # Guardar copia de los pesos de mask\n",
    "    # mask_before = [p.clone().detach() for p in mask.parameters()]\n",
    "\n",
    "    for batch_idx, (images, labels) in enumerate(train_loader):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "    \n",
    "        optimizer.zero_grad()\n",
    "        outputs = masked_model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "\n",
    "        # # Verificar gradientes\n",
    "        # for name, param in mask.named_parameters():\n",
    "        #     if param.grad is not None:\n",
    "        #         print(f\"[Grad] {name}: grad norm = {param.grad.norm().item():.6f}\")\n",
    "        #     else:\n",
    "        #         print(f\"[Grad] {name}: NO grad\")\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        # if batch_idx % 10 == 0:\n",
    "        #     print(f\"Batch {batch_idx}, Loss: {loss.item():.4f}\")\n",
    "\n",
    "    avg_loss = running_loss / len(train_loader)\n",
    "    losses.append(avg_loss)\n",
    "\n",
    "    # Evaluación\n",
    "    masked_model.eval()\n",
    "    correct, total = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = masked_model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = 100.0 * correct / total\n",
    "    accuracies.append(accuracy)\n",
    "\n",
    "    #     # Verificar cambios en los parámetros de mask\n",
    "    # for (before, after), name in zip(zip(mask_before, mask.parameters()), mask.state_dict().keys()):\n",
    "    #     delta = (after - before).abs().sum().item()\n",
    "    #     print(f\"[Update] {name}: Δ = {delta:.6f}\")\n",
    "\n",
    "    # # Verificar que net no ha sido modificado\n",
    "    # for (before, after), name in zip(zip(net_before, net.parameters()), net.state_dict().keys()):\n",
    "    #     delta = (after - before).abs().sum().item()\n",
    "    #     print(f\"[Check Net] {name}: Δ = {delta:.6f}\")\n",
    "\n",
    "    print(f\"Epoch {epoch}: Avg Loss = {avg_loss:.4f}, Test Accuracy = {accuracy:.2f}%\")\n",
    "\n",
    "    if accuracy >= threshold_accuracy * 100:\n",
    "        print(\"Reached target accuracy. Stopping training.\")\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9dfcbb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gráficos de pérdida y precisión\n",
    "plt.figure()\n",
    "plt.plot(range(1, len(losses)+1), losses, label='Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss per Epoch')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(range(1, len(accuracies)+1), accuracies, label='Accuracy', color='green')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.title('Test Accuracy per Epoch')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
